{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 08:45:29.451135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 08:45:29.559088: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-20 08:45:29.934906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-20 08:45:29.934941: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-20 08:45:29.934945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "## Load the library: \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model_creation_torch import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/hieunguyen/Desktop/MlSupervise/Experiment/experiment/make_data_spd2spd.py': [Errno 2] No such file or directory\n",
      "python: can't open file '/home/hieunguyen/Desktop/MlSupervise/Experiment/experiment/make_data_spd2spd.py': [Errno 2] No such file or directory\n",
      "python: can't open file '/home/hieunguyen/Desktop/MlSupervise/Experiment/experiment/make_data_spd2spd.py': [Errno 2] No such file or directory\n",
      "python: can't open file '/home/hieunguyen/Desktop/MlSupervise/Experiment/experiment/make_data_spd2spd.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Create the data:\n",
    "\n",
    "\n",
    "!python make_data_spd2spd.py  10000 5 20 10\n",
    "!python make_data_spd2spd.py  10000 20 20 10\n",
    "!python make_data_spd2spd.py  10000 5 40 20\n",
    "!python make_data_spd2spd.py  10000 20 40 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1949.769531  [   32/10000]\n",
      "loss: 847.845520  [ 3232/10000]\n",
      "loss: 381.060913  [ 6432/10000]\n",
      "loss: 174.854614  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 147.197841 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 156.910019  [   32/10000]\n",
      "loss: 70.730721  [ 3232/10000]\n",
      "loss: 36.338036  [ 6432/10000]\n",
      "loss: 25.079008  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 23.794551 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 24.044706  [   32/10000]\n",
      "loss: 18.064627  [ 3232/10000]\n",
      "loss: 16.007248  [ 6432/10000]\n",
      "loss: 13.088305  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 12.438760 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 11.362957  [   32/10000]\n",
      "loss: 10.122611  [ 3232/10000]\n",
      "loss: 8.399564  [ 6432/10000]\n",
      "loss: 7.301431  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.337085 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 7.065270  [   32/10000]\n",
      "loss: 5.468819  [ 3232/10000]\n",
      "loss: 5.041320  [ 6432/10000]\n",
      "loss: 3.803230  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.703587 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.160865  [   32/10000]\n",
      "loss: 4.105968  [ 3232/10000]\n",
      "loss: 3.552755  [ 6432/10000]\n",
      "loss: 3.642173  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.423738 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.915596  [   32/10000]\n",
      "loss: 3.159868  [ 3232/10000]\n",
      "loss: 2.629495  [ 6432/10000]\n",
      "loss: 2.670756  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.775946 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.410625  [   32/10000]\n",
      "loss: 2.255013  [ 3232/10000]\n",
      "loss: 2.252785  [ 6432/10000]\n",
      "loss: 2.275811  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.397149 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.113491  [   32/10000]\n",
      "loss: 2.435759  [ 3232/10000]\n",
      "loss: 2.696423  [ 6432/10000]\n",
      "loss: 2.413256  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.112591 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.938177  [   32/10000]\n",
      "loss: 1.952784  [ 3232/10000]\n",
      "loss: 2.419557  [ 6432/10000]\n",
      "loss: 2.149276  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.865379 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.078425  [   32/10000]\n",
      "loss: 1.643423  [ 3232/10000]\n",
      "loss: 1.793329  [ 6432/10000]\n",
      "loss: 1.569842  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.624599 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.441237  [   32/10000]\n",
      "loss: 1.674513  [ 3232/10000]\n",
      "loss: 1.598490  [ 6432/10000]\n",
      "loss: 1.410678  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.390574 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.528433  [   32/10000]\n",
      "loss: 1.190734  [ 3232/10000]\n",
      "loss: 1.405723  [ 6432/10000]\n",
      "loss: 1.016936  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.162741 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.223893  [   32/10000]\n",
      "loss: 0.886131  [ 3232/10000]\n",
      "loss: 0.985531  [ 6432/10000]\n",
      "loss: 0.906649  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.948309 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.936280  [   32/10000]\n",
      "loss: 0.767384  [ 3232/10000]\n",
      "loss: 0.742150  [ 6432/10000]\n",
      "loss: 0.770103  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.742923 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.802685  [   32/10000]\n",
      "loss: 0.763286  [ 3232/10000]\n",
      "loss: 0.651814  [ 6432/10000]\n",
      "loss: 0.581553  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.572124 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.459503  [   32/10000]\n",
      "loss: 0.529028  [ 3232/10000]\n",
      "loss: 0.407771  [ 6432/10000]\n",
      "loss: 0.340820  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.414581 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.443239  [   32/10000]\n",
      "loss: 0.380597  [ 3232/10000]\n",
      "loss: 0.288174  [ 6432/10000]\n",
      "loss: 0.315700  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.288018 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.272395  [   32/10000]\n",
      "loss: 0.264458  [ 3232/10000]\n",
      "loss: 0.293746  [ 6432/10000]\n",
      "loss: 0.179043  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.192830 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.196689  [   32/10000]\n",
      "loss: 0.157375  [ 3232/10000]\n",
      "loss: 0.143474  [ 6432/10000]\n",
      "loss: 0.092548  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.118430 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.118607  [   32/10000]\n",
      "loss: 0.088129  [ 3232/10000]\n",
      "loss: 0.075772  [ 6432/10000]\n",
      "loss: 0.082045  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.069791 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.066339  [   32/10000]\n",
      "loss: 0.061751  [ 3232/10000]\n",
      "loss: 0.058803  [ 6432/10000]\n",
      "loss: 0.038707  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.041658 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.038011  [   32/10000]\n",
      "loss: 0.033376  [ 3232/10000]\n",
      "loss: 0.028402  [ 6432/10000]\n",
      "loss: 0.027583  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.028461 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.030135  [   32/10000]\n",
      "loss: 0.034575  [ 3232/10000]\n",
      "loss: 0.025186  [ 6432/10000]\n",
      "loss: 0.021498  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.020008 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.019028  [   32/10000]\n",
      "loss: 0.029385  [ 3232/10000]\n",
      "loss: 0.030174  [ 6432/10000]\n",
      "loss: 0.021709  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.027821 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.027012  [   32/10000]\n",
      "loss: 0.027220  [ 3232/10000]\n",
      "loss: 0.022209  [ 6432/10000]\n",
      "loss: 0.016420  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.017810 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.015440  [   32/10000]\n",
      "loss: 0.017742  [ 3232/10000]\n",
      "loss: 0.024241  [ 6432/10000]\n",
      "loss: 0.017242  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.018907 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.019490  [   32/10000]\n",
      "loss: 0.016901  [ 3232/10000]\n",
      "loss: 0.020088  [ 6432/10000]\n",
      "loss: 0.024544  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.027067 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.026322  [   32/10000]\n",
      "loss: 0.028613  [ 3232/10000]\n",
      "loss: 0.036756  [ 6432/10000]\n",
      "loss: 0.027516  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.023645 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.023755  [   32/10000]\n",
      "loss: 0.020914  [ 3232/10000]\n",
      "loss: 0.017930  [ 6432/10000]\n",
      "loss: 0.017763  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.016231 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1667.423096  [   32/10000]\n",
      "loss: 949.197815  [ 3232/10000]\n",
      "loss: 332.670074  [ 6432/10000]\n",
      "loss: 280.567413  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 294.775332 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 316.442566  [   32/10000]\n",
      "loss: 323.452118  [ 3232/10000]\n",
      "loss: 286.637238  [ 6432/10000]\n",
      "loss: 250.807358  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 249.630428 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 233.706894  [   32/10000]\n",
      "loss: 236.528870  [ 3232/10000]\n",
      "loss: 212.120316  [ 6432/10000]\n",
      "loss: 176.717377  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 173.367228 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 180.922928  [   32/10000]\n",
      "loss: 133.230942  [ 3232/10000]\n",
      "loss: 117.917717  [ 6432/10000]\n",
      "loss: 92.718124  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 95.397678 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 86.778175  [   32/10000]\n",
      "loss: 79.672943  [ 3232/10000]\n",
      "loss: 58.245342  [ 6432/10000]\n",
      "loss: 46.111237  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 43.109074 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 42.394390  [   32/10000]\n",
      "loss: 30.115740  [ 3232/10000]\n",
      "loss: 20.156231  [ 6432/10000]\n",
      "loss: 12.562822  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.182261 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 9.602930  [   32/10000]\n",
      "loss: 5.734768  [ 3232/10000]\n",
      "loss: 3.160218  [ 6432/10000]\n",
      "loss: 1.473259  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.425937 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.462377  [   32/10000]\n",
      "loss: 0.635254  [ 3232/10000]\n",
      "loss: 0.312922  [ 6432/10000]\n",
      "loss: 0.155293  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.126598 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.138257  [   32/10000]\n",
      "loss: 0.054998  [ 3232/10000]\n",
      "loss: 0.021131  [ 6432/10000]\n",
      "loss: 0.009886  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.008604 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.008500  [   32/10000]\n",
      "loss: 0.003450  [ 3232/10000]\n",
      "loss: 0.001267  [ 6432/10000]\n",
      "loss: 0.000506  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000422 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000408  [   32/10000]\n",
      "loss: 0.000124  [ 3232/10000]\n",
      "loss: 0.000046  [ 6432/10000]\n",
      "loss: 0.000016  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000013 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/10000]\n",
      "loss: 0.000004  [ 3232/10000]\n",
      "loss: 0.000001  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1898.295654  [   32/10000]\n",
      "loss: 145.706482  [ 3232/10000]\n",
      "loss: 134.071869  [ 6432/10000]\n",
      "loss: 110.660782  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 109.471414 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 105.176117  [   32/10000]\n",
      "loss: 87.153381  [ 3232/10000]\n",
      "loss: 72.694588  [ 6432/10000]\n",
      "loss: 57.425369  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 55.041740 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 58.009243  [   32/10000]\n",
      "loss: 38.830051  [ 3232/10000]\n",
      "loss: 38.042526  [ 6432/10000]\n",
      "loss: 33.282143  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 29.960825 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 33.170364  [   32/10000]\n",
      "loss: 24.847876  [ 3232/10000]\n",
      "loss: 19.838938  [ 6432/10000]\n",
      "loss: 19.336931  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 18.243609 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 17.821434  [   32/10000]\n",
      "loss: 16.875860  [ 3232/10000]\n",
      "loss: 13.647823  [ 6432/10000]\n",
      "loss: 11.503314  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.517361 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 11.418522  [   32/10000]\n",
      "loss: 10.686889  [ 3232/10000]\n",
      "loss: 7.967433  [ 6432/10000]\n",
      "loss: 8.149952  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.591477 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 8.060475  [   32/10000]\n",
      "loss: 7.654809  [ 3232/10000]\n",
      "loss: 5.196409  [ 6432/10000]\n",
      "loss: 4.820557  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.441903 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.866204  [   32/10000]\n",
      "loss: 5.926168  [ 3232/10000]\n",
      "loss: 4.684227  [ 6432/10000]\n",
      "loss: 4.458655  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.328529 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.853676  [   32/10000]\n",
      "loss: 3.909731  [ 3232/10000]\n",
      "loss: 3.148250  [ 6432/10000]\n",
      "loss: 3.707465  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.650799 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.768488  [   32/10000]\n",
      "loss: 3.417434  [ 3232/10000]\n",
      "loss: 3.751736  [ 6432/10000]\n",
      "loss: 3.305227  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.346914 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 3.342439  [   32/10000]\n",
      "loss: 3.107442  [ 3232/10000]\n",
      "loss: 3.173245  [ 6432/10000]\n",
      "loss: 3.407312  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.230955 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 3.431674  [   32/10000]\n",
      "loss: 2.692722  [ 3232/10000]\n",
      "loss: 3.504899  [ 6432/10000]\n",
      "loss: 3.311421  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.211273 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.901219  [   32/10000]\n",
      "loss: 3.499880  [ 3232/10000]\n",
      "loss: 4.053004  [ 6432/10000]\n",
      "loss: 2.380178  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.021756 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.624792  [   32/10000]\n",
      "loss: 3.012596  [ 3232/10000]\n",
      "loss: 2.881895  [ 6432/10000]\n",
      "loss: 2.365757  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.028011 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.583705  [   32/10000]\n",
      "loss: 2.754408  [ 3232/10000]\n",
      "loss: 3.383031  [ 6432/10000]\n",
      "loss: 3.064211  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.039673 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3.301876  [   32/10000]\n",
      "loss: 2.922008  [ 3232/10000]\n",
      "loss: 2.696084  [ 6432/10000]\n",
      "loss: 2.889897  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.977777 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.914696  [   32/10000]\n",
      "loss: 2.861921  [ 3232/10000]\n",
      "loss: 2.190318  [ 6432/10000]\n",
      "loss: 2.998833  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.039151 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.416883  [   32/10000]\n",
      "loss: 2.534109  [ 3232/10000]\n",
      "loss: 3.025478  [ 6432/10000]\n",
      "loss: 4.046120  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.002010 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.895543  [   32/10000]\n",
      "loss: 3.406970  [ 3232/10000]\n",
      "loss: 2.762908  [ 6432/10000]\n",
      "loss: 3.458660  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.095762 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3.016038  [   32/10000]\n",
      "loss: 3.688205  [ 3232/10000]\n",
      "loss: 3.632524  [ 6432/10000]\n",
      "loss: 3.242840  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.997754 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.863256  [   32/10000]\n",
      "loss: 3.322468  [ 3232/10000]\n",
      "loss: 2.711727  [ 6432/10000]\n",
      "loss: 2.769158  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.038672 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.800192  [   32/10000]\n",
      "loss: 2.705021  [ 3232/10000]\n",
      "loss: 3.170654  [ 6432/10000]\n",
      "loss: 2.948110  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.177946 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.886706  [   32/10000]\n",
      "loss: 3.921998  [ 3232/10000]\n",
      "loss: 2.429852  [ 6432/10000]\n",
      "loss: 2.766472  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.146942 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.759718  [   32/10000]\n",
      "loss: 3.044984  [ 3232/10000]\n",
      "loss: 2.978276  [ 6432/10000]\n",
      "loss: 3.283137  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.026470 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.619629  [   32/10000]\n",
      "loss: 2.675538  [ 3232/10000]\n",
      "loss: 3.062665  [ 6432/10000]\n",
      "loss: 2.758496  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.985585 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 3.096210  [   32/10000]\n",
      "loss: 3.261677  [ 3232/10000]\n",
      "loss: 3.179393  [ 6432/10000]\n",
      "loss: 3.333948  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.157019 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.895411  [   32/10000]\n",
      "loss: 4.219744  [ 3232/10000]\n",
      "loss: 2.572309  [ 6432/10000]\n",
      "loss: 3.113919  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.129892 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.691036  [   32/10000]\n",
      "loss: 3.444572  [ 3232/10000]\n",
      "loss: 2.766131  [ 6432/10000]\n",
      "loss: 3.163892  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.052261 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.793427  [   32/10000]\n",
      "loss: 3.122831  [ 3232/10000]\n",
      "loss: 2.780097  [ 6432/10000]\n",
      "loss: 3.327623  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.142863 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.250824  [   32/10000]\n",
      "loss: 2.866309  [ 3232/10000]\n",
      "loss: 2.611814  [ 6432/10000]\n",
      "loss: 3.071933  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.065028 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1818.078003  [   32/10000]\n",
      "loss: 788.961426  [ 3232/10000]\n",
      "loss: 371.786804  [ 6432/10000]\n",
      "loss: 172.321762  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 145.511295 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 150.925369  [   32/10000]\n",
      "loss: 70.164940  [ 3232/10000]\n",
      "loss: 38.527428  [ 6432/10000]\n",
      "loss: 26.005987  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 23.362871 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 22.415077  [   32/10000]\n",
      "loss: 18.124018  [ 3232/10000]\n",
      "loss: 13.955348  [ 6432/10000]\n",
      "loss: 13.285043  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 12.245991 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 12.076233  [   32/10000]\n",
      "loss: 10.358203  [ 3232/10000]\n",
      "loss: 8.961538  [ 6432/10000]\n",
      "loss: 6.991425  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.212612 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 6.446692  [   32/10000]\n",
      "loss: 5.805227  [ 3232/10000]\n",
      "loss: 4.855661  [ 6432/10000]\n",
      "loss: 3.776596  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.591942 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.708373  [   32/10000]\n",
      "loss: 4.025351  [ 3232/10000]\n",
      "loss: 3.305067  [ 6432/10000]\n",
      "loss: 3.270608  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.307396 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.788169  [   32/10000]\n",
      "loss: 3.084047  [ 3232/10000]\n",
      "loss: 2.699974  [ 6432/10000]\n",
      "loss: 2.997994  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.680604 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.186702  [   32/10000]\n",
      "loss: 2.481754  [ 3232/10000]\n",
      "loss: 1.986861  [ 6432/10000]\n",
      "loss: 2.069181  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.312076 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.368054  [   32/10000]\n",
      "loss: 1.915276  [ 3232/10000]\n",
      "loss: 1.671094  [ 6432/10000]\n",
      "loss: 2.180938  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.042972 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.246281  [   32/10000]\n",
      "loss: 1.921990  [ 3232/10000]\n",
      "loss: 1.854087  [ 6432/10000]\n",
      "loss: 1.556069  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.808997 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.014113  [   32/10000]\n",
      "loss: 1.357588  [ 3232/10000]\n",
      "loss: 1.759107  [ 6432/10000]\n",
      "loss: 1.677423  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.580750 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.493348  [   32/10000]\n",
      "loss: 1.936377  [ 3232/10000]\n",
      "loss: 1.454655  [ 6432/10000]\n",
      "loss: 1.470213  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.354980 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.535906  [   32/10000]\n",
      "loss: 1.335946  [ 3232/10000]\n",
      "loss: 1.442826  [ 6432/10000]\n",
      "loss: 1.040769  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.134302 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.027839  [   32/10000]\n",
      "loss: 1.100572  [ 3232/10000]\n",
      "loss: 0.997676  [ 6432/10000]\n",
      "loss: 1.015586  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.922753 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.787695  [   32/10000]\n",
      "loss: 0.780516  [ 3232/10000]\n",
      "loss: 0.729432  [ 6432/10000]\n",
      "loss: 0.762500  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.730255 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.683889  [   32/10000]\n",
      "loss: 0.664042  [ 3232/10000]\n",
      "loss: 0.531763  [ 6432/10000]\n",
      "loss: 0.490569  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.557057 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.438659  [   32/10000]\n",
      "loss: 0.421677  [ 3232/10000]\n",
      "loss: 0.384145  [ 6432/10000]\n",
      "loss: 0.349011  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.409586 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.443597  [   32/10000]\n",
      "loss: 0.365337  [ 3232/10000]\n",
      "loss: 0.334446  [ 6432/10000]\n",
      "loss: 0.324901  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.286155 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.253593  [   32/10000]\n",
      "loss: 0.245119  [ 3232/10000]\n",
      "loss: 0.187513  [ 6432/10000]\n",
      "loss: 0.191793  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.189949 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.180891  [   32/10000]\n",
      "loss: 0.151877  [ 3232/10000]\n",
      "loss: 0.128930  [ 6432/10000]\n",
      "loss: 0.136670  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.118972 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.111409  [   32/10000]\n",
      "loss: 0.109845  [ 3232/10000]\n",
      "loss: 0.084494  [ 6432/10000]\n",
      "loss: 0.056995  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.070111 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.063427  [   32/10000]\n",
      "loss: 0.053015  [ 3232/10000]\n",
      "loss: 0.053189  [ 6432/10000]\n",
      "loss: 0.045346  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.047782 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.049573  [   32/10000]\n",
      "loss: 0.040135  [ 3232/10000]\n",
      "loss: 0.036133  [ 6432/10000]\n",
      "loss: 0.035335  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.027838 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.028024  [   32/10000]\n",
      "loss: 0.029292  [ 3232/10000]\n",
      "loss: 0.025487  [ 6432/10000]\n",
      "loss: 0.027664  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.025457 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.027247  [   32/10000]\n",
      "loss: 0.021649  [ 3232/10000]\n",
      "loss: 0.021146  [ 6432/10000]\n",
      "loss: 0.023013  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.028924 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.029202  [   32/10000]\n",
      "loss: 0.021228  [ 3232/10000]\n",
      "loss: 0.050075  [ 6432/10000]\n",
      "loss: 0.037945  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.033444 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.029318  [   32/10000]\n",
      "loss: 0.022510  [ 3232/10000]\n",
      "loss: 0.016605  [ 6432/10000]\n",
      "loss: 0.016084  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.017143 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.015821  [   32/10000]\n",
      "loss: 0.014935  [ 3232/10000]\n",
      "loss: 0.014581  [ 6432/10000]\n",
      "loss: 0.017163  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.017380 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.017699  [   32/10000]\n",
      "loss: 0.019757  [ 3232/10000]\n",
      "loss: 0.021520  [ 6432/10000]\n",
      "loss: 0.030308  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.032809 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.028855  [   32/10000]\n",
      "loss: 0.040326  [ 3232/10000]\n",
      "loss: 0.030631  [ 6432/10000]\n",
      "loss: 0.029964  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.025664 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 35199.125000  [   32/10000]\n",
      "loss: 28784.210938  [ 3232/10000]\n",
      "loss: 25167.464844  [ 6432/10000]\n",
      "loss: 21499.761719  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 20908.838989 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 19692.056641  [   32/10000]\n",
      "loss: 17141.087891  [ 3232/10000]\n",
      "loss: 14947.410156  [ 6432/10000]\n",
      "loss: 12736.241211  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 12331.411865 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 12361.867188  [   32/10000]\n",
      "loss: 10289.170898  [ 3232/10000]\n",
      "loss: 8541.977539  [ 6432/10000]\n",
      "loss: 6783.918945  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6806.894119 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 6734.390137  [   32/10000]\n",
      "loss: 5528.729492  [ 3232/10000]\n",
      "loss: 4338.251953  [ 6432/10000]\n",
      "loss: 3591.037109  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3477.309723 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3358.849121  [   32/10000]\n",
      "loss: 2492.566406  [ 3232/10000]\n",
      "loss: 2157.589111  [ 6432/10000]\n",
      "loss: 1762.167358  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1633.701294 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1585.716553  [   32/10000]\n",
      "loss: 1316.394043  [ 3232/10000]\n",
      "loss: 989.654785  [ 6432/10000]\n",
      "loss: 783.890381  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 716.135132 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 693.346924  [   32/10000]\n",
      "loss: 460.925049  [ 3232/10000]\n",
      "loss: 409.596008  [ 6432/10000]\n",
      "loss: 306.095154  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 311.082169 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 301.290710  [   32/10000]\n",
      "loss: 237.599915  [ 3232/10000]\n",
      "loss: 194.022873  [ 6432/10000]\n",
      "loss: 139.900345  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 151.952106 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 137.448318  [   32/10000]\n",
      "loss: 110.562370  [ 3232/10000]\n",
      "loss: 100.496834  [ 6432/10000]\n",
      "loss: 87.262932  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 93.062222 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 68.780548  [   32/10000]\n",
      "loss: 79.099091  [ 3232/10000]\n",
      "loss: 71.350342  [ 6432/10000]\n",
      "loss: 68.232117  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 68.351012 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 74.609749  [   32/10000]\n",
      "loss: 56.134995  [ 3232/10000]\n",
      "loss: 55.139652  [ 6432/10000]\n",
      "loss: 53.992077  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 53.836793 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 54.981514  [   32/10000]\n",
      "loss: 47.239368  [ 3232/10000]\n",
      "loss: 46.492657  [ 6432/10000]\n",
      "loss: 42.704185  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 42.908194 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 41.794586  [   32/10000]\n",
      "loss: 35.081028  [ 3232/10000]\n",
      "loss: 36.051861  [ 6432/10000]\n",
      "loss: 31.819653  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 34.035932 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 33.445702  [   32/10000]\n",
      "loss: 24.656370  [ 3232/10000]\n",
      "loss: 30.205227  [ 6432/10000]\n",
      "loss: 29.030787  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 27.013771 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 31.939228  [   32/10000]\n",
      "loss: 20.773838  [ 3232/10000]\n",
      "loss: 25.233637  [ 6432/10000]\n",
      "loss: 21.050547  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 21.653377 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 21.155170  [   32/10000]\n",
      "loss: 18.346405  [ 3232/10000]\n",
      "loss: 18.747309  [ 6432/10000]\n",
      "loss: 16.183813  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 17.745175 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 15.820697  [   32/10000]\n",
      "loss: 14.722717  [ 3232/10000]\n",
      "loss: 14.519770  [ 6432/10000]\n",
      "loss: 12.736222  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.997605 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 14.481655  [   32/10000]\n",
      "loss: 14.472067  [ 3232/10000]\n",
      "loss: 15.524899  [ 6432/10000]\n",
      "loss: 13.685432  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 13.146562 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 11.060752  [   32/10000]\n",
      "loss: 12.421536  [ 3232/10000]\n",
      "loss: 11.608556  [ 6432/10000]\n",
      "loss: 9.850795  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.885941 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 10.707458  [   32/10000]\n",
      "loss: 9.415530  [ 3232/10000]\n",
      "loss: 10.096622  [ 6432/10000]\n",
      "loss: 10.025393  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.984356 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 9.983471  [   32/10000]\n",
      "loss: 10.524623  [ 3232/10000]\n",
      "loss: 10.891842  [ 6432/10000]\n",
      "loss: 9.383108  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.248525 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 10.424756  [   32/10000]\n",
      "loss: 9.282075  [ 3232/10000]\n",
      "loss: 8.596582  [ 6432/10000]\n",
      "loss: 9.368198  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.575519 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 8.468147  [   32/10000]\n",
      "loss: 9.465725  [ 3232/10000]\n",
      "loss: 8.423414  [ 6432/10000]\n",
      "loss: 9.093498  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.896592 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 8.329967  [   32/10000]\n",
      "loss: 9.666245  [ 3232/10000]\n",
      "loss: 9.915590  [ 6432/10000]\n",
      "loss: 8.384608  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.186707 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 7.425032  [   32/10000]\n",
      "loss: 6.979810  [ 3232/10000]\n",
      "loss: 7.949696  [ 6432/10000]\n",
      "loss: 6.092169  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.427874 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 6.760011  [   32/10000]\n",
      "loss: 6.504778  [ 3232/10000]\n",
      "loss: 6.814584  [ 6432/10000]\n",
      "loss: 6.323477  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6.645797 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 6.990867  [   32/10000]\n",
      "loss: 6.258518  [ 3232/10000]\n",
      "loss: 6.576249  [ 6432/10000]\n",
      "loss: 6.511784  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.834813 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 5.676035  [   32/10000]\n",
      "loss: 5.107437  [ 3232/10000]\n",
      "loss: 5.301275  [ 6432/10000]\n",
      "loss: 4.565757  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.007668 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4.002661  [   32/10000]\n",
      "loss: 4.017645  [ 3232/10000]\n",
      "loss: 4.852191  [ 6432/10000]\n",
      "loss: 3.902029  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.212984 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.542986  [   32/10000]\n",
      "loss: 3.607798  [ 3232/10000]\n",
      "loss: 3.733043  [ 6432/10000]\n",
      "loss: 3.028929  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.442144 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31877.177734  [   32/10000]\n",
      "loss: 16125.040039  [ 3232/10000]\n",
      "loss: 2501.777100  [ 6432/10000]\n",
      "loss: 1683.391235  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1727.558331 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1744.999390  [   32/10000]\n",
      "loss: 1689.941528  [ 3232/10000]\n",
      "loss: 1691.228882  [ 6432/10000]\n",
      "loss: 1440.290649  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1522.950905 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1440.177979  [   32/10000]\n",
      "loss: 1511.655762  [ 3232/10000]\n",
      "loss: 1394.135986  [ 6432/10000]\n",
      "loss: 1186.010620  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1269.764900 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1219.614990  [   32/10000]\n",
      "loss: 1289.152344  [ 3232/10000]\n",
      "loss: 1083.754639  [ 6432/10000]\n",
      "loss: 1055.961304  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 994.550880 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1010.545227  [   32/10000]\n",
      "loss: 971.331238  [ 3232/10000]\n",
      "loss: 850.574036  [ 6432/10000]\n",
      "loss: 782.894348  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 742.540823 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 750.801392  [   32/10000]\n",
      "loss: 698.599121  [ 3232/10000]\n",
      "loss: 533.246887  [ 6432/10000]\n",
      "loss: 593.756104  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 541.182281 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 521.460083  [   32/10000]\n",
      "loss: 461.418640  [ 3232/10000]\n",
      "loss: 467.359558  [ 6432/10000]\n",
      "loss: 393.987427  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 392.492207 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 357.124390  [   32/10000]\n",
      "loss: 377.818970  [ 3232/10000]\n",
      "loss: 332.219482  [ 6432/10000]\n",
      "loss: 304.433716  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 286.872765 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 286.395782  [   32/10000]\n",
      "loss: 271.819641  [ 3232/10000]\n",
      "loss: 236.583374  [ 6432/10000]\n",
      "loss: 202.552170  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 209.951632 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 211.184921  [   32/10000]\n",
      "loss: 195.458649  [ 3232/10000]\n",
      "loss: 170.458984  [ 6432/10000]\n",
      "loss: 147.970291  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 152.637518 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 149.078903  [   32/10000]\n",
      "loss: 126.872658  [ 3232/10000]\n",
      "loss: 127.402435  [ 6432/10000]\n",
      "loss: 104.254532  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 107.282205 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 107.935768  [   32/10000]\n",
      "loss: 100.989609  [ 3232/10000]\n",
      "loss: 78.684914  [ 6432/10000]\n",
      "loss: 68.593109  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 71.544817 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 65.686928  [   32/10000]\n",
      "loss: 62.256393  [ 3232/10000]\n",
      "loss: 49.089359  [ 6432/10000]\n",
      "loss: 45.691547  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 44.403441 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 45.545654  [   32/10000]\n",
      "loss: 36.613136  [ 3232/10000]\n",
      "loss: 31.316177  [ 6432/10000]\n",
      "loss: 26.650452  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 25.853683 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 22.283150  [   32/10000]\n",
      "loss: 21.636650  [ 3232/10000]\n",
      "loss: 16.887531  [ 6432/10000]\n",
      "loss: 15.641771  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.862499 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 14.735205  [   32/10000]\n",
      "loss: 12.472743  [ 3232/10000]\n",
      "loss: 10.288783  [ 6432/10000]\n",
      "loss: 9.451648  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.181541 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 9.200293  [   32/10000]\n",
      "loss: 7.394529  [ 3232/10000]\n",
      "loss: 6.618898  [ 6432/10000]\n",
      "loss: 5.331213  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.715815 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 5.710363  [   32/10000]\n",
      "loss: 4.773547  [ 3232/10000]\n",
      "loss: 3.831872  [ 6432/10000]\n",
      "loss: 2.891260  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.706634 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.815665  [   32/10000]\n",
      "loss: 2.029107  [ 3232/10000]\n",
      "loss: 1.246115  [ 6432/10000]\n",
      "loss: 0.840474  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.744449 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.765962  [   32/10000]\n",
      "loss: 0.455248  [ 3232/10000]\n",
      "loss: 0.295301  [ 6432/10000]\n",
      "loss: 0.152631  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.138246 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.134619  [   32/10000]\n",
      "loss: 0.078767  [ 3232/10000]\n",
      "loss: 0.040399  [ 6432/10000]\n",
      "loss: 0.024169  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.020283 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.021154  [   32/10000]\n",
      "loss: 0.010125  [ 3232/10000]\n",
      "loss: 0.005567  [ 6432/10000]\n",
      "loss: 0.002826  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.002412 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.002422  [   32/10000]\n",
      "loss: 0.001121  [ 3232/10000]\n",
      "loss: 0.000499  [ 6432/10000]\n",
      "loss: 0.000253  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000232 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000259  [   32/10000]\n",
      "loss: 0.000107  [ 3232/10000]\n",
      "loss: 0.000052  [ 6432/10000]\n",
      "loss: 0.000017  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000016 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/10000]\n",
      "loss: 0.000007  [ 3232/10000]\n",
      "loss: 0.000003  [ 6432/10000]\n",
      "loss: 0.000001  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000001 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000001  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34477.058594  [   32/10000]\n",
      "loss: 946.751892  [ 3232/10000]\n",
      "loss: 844.228149  [ 6432/10000]\n",
      "loss: 778.628418  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 746.732929 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 765.213135  [   32/10000]\n",
      "loss: 663.589478  [ 3232/10000]\n",
      "loss: 518.084900  [ 6432/10000]\n",
      "loss: 400.226257  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 371.665275 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 357.268372  [   32/10000]\n",
      "loss: 276.581360  [ 3232/10000]\n",
      "loss: 222.128220  [ 6432/10000]\n",
      "loss: 167.866364  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 160.327511 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 158.889847  [   32/10000]\n",
      "loss: 131.719955  [ 3232/10000]\n",
      "loss: 107.597511  [ 6432/10000]\n",
      "loss: 79.664383  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 84.864377 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 89.803337  [   32/10000]\n",
      "loss: 65.582161  [ 3232/10000]\n",
      "loss: 56.569321  [ 6432/10000]\n",
      "loss: 55.082230  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 51.071563 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 48.301891  [   32/10000]\n",
      "loss: 43.158417  [ 3232/10000]\n",
      "loss: 36.854092  [ 6432/10000]\n",
      "loss: 37.792679  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 32.919909 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 25.977577  [   32/10000]\n",
      "loss: 25.507769  [ 3232/10000]\n",
      "loss: 28.158863  [ 6432/10000]\n",
      "loss: 21.946440  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 21.481337 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 20.806581  [   32/10000]\n",
      "loss: 17.631756  [ 3232/10000]\n",
      "loss: 15.188468  [ 6432/10000]\n",
      "loss: 13.621904  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 12.833435 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 12.376057  [   32/10000]\n",
      "loss: 11.440836  [ 3232/10000]\n",
      "loss: 8.518737  [ 6432/10000]\n",
      "loss: 6.799074  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.659023 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 6.993380  [   32/10000]\n",
      "loss: 6.598143  [ 3232/10000]\n",
      "loss: 4.351766  [ 6432/10000]\n",
      "loss: 3.765936  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.555741 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.343509  [   32/10000]\n",
      "loss: 4.421965  [ 3232/10000]\n",
      "loss: 2.909952  [ 6432/10000]\n",
      "loss: 2.847964  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.662863 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.126335  [   32/10000]\n",
      "loss: 1.971132  [ 3232/10000]\n",
      "loss: 1.703763  [ 6432/10000]\n",
      "loss: 1.509991  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.581438 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.514711  [   32/10000]\n",
      "loss: 1.264311  [ 3232/10000]\n",
      "loss: 1.069084  [ 6432/10000]\n",
      "loss: 0.810214  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.870968 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.854519  [   32/10000]\n",
      "loss: 0.612478  [ 3232/10000]\n",
      "loss: 0.515320  [ 6432/10000]\n",
      "loss: 0.437652  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.458466 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.483298  [   32/10000]\n",
      "loss: 0.328775  [ 3232/10000]\n",
      "loss: 0.219269  [ 6432/10000]\n",
      "loss: 0.205112  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.199792 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.170576  [   32/10000]\n",
      "loss: 0.153198  [ 3232/10000]\n",
      "loss: 0.119715  [ 6432/10000]\n",
      "loss: 0.079437  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.087413 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.097405  [   32/10000]\n",
      "loss: 0.063373  [ 3232/10000]\n",
      "loss: 0.045032  [ 6432/10000]\n",
      "loss: 0.042001  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.041241 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.034674  [   32/10000]\n",
      "loss: 0.031861  [ 3232/10000]\n",
      "loss: 0.025278  [ 6432/10000]\n",
      "loss: 0.020600  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.020290 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.019725  [   32/10000]\n",
      "loss: 0.018349  [ 3232/10000]\n",
      "loss: 0.037985  [ 6432/10000]\n",
      "loss: 0.071709  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.071326 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.061165  [   32/10000]\n",
      "loss: 0.438887  [ 3232/10000]\n",
      "loss: 0.552280  [ 6432/10000]\n",
      "loss: 1.006942  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.516987 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.478889  [   32/10000]\n",
      "loss: 1.435046  [ 3232/10000]\n",
      "loss: 0.860777  [ 6432/10000]\n",
      "loss: 0.505298  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.551568 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.464551  [   32/10000]\n",
      "loss: 0.381133  [ 3232/10000]\n",
      "loss: 1.394176  [ 6432/10000]\n",
      "loss: 0.532505  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.971754 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.776191  [   32/10000]\n",
      "loss: 0.867404  [ 3232/10000]\n",
      "loss: 0.690255  [ 6432/10000]\n",
      "loss: 2.135522  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.427572 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.166809  [   32/10000]\n",
      "loss: 1.289756  [ 3232/10000]\n",
      "loss: 0.270061  [ 6432/10000]\n",
      "loss: 0.198333  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.176342 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.141456  [   32/10000]\n",
      "loss: 0.313451  [ 3232/10000]\n",
      "loss: 0.228246  [ 6432/10000]\n",
      "loss: 0.520355  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.826984 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.627197  [   32/10000]\n",
      "loss: 1.182574  [ 3232/10000]\n",
      "loss: 3.492550  [ 6432/10000]\n",
      "loss: 0.643512  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.605020 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.446623  [   32/10000]\n",
      "loss: 0.201705  [ 3232/10000]\n",
      "loss: 0.156901  [ 6432/10000]\n",
      "loss: 0.176435  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.306684 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.288467  [   32/10000]\n",
      "loss: 0.338928  [ 3232/10000]\n",
      "loss: 0.728785  [ 6432/10000]\n",
      "loss: 1.370702  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.298878 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.395440  [   32/10000]\n",
      "loss: 1.061927  [ 3232/10000]\n",
      "loss: 2.083934  [ 6432/10000]\n",
      "loss: 1.567655  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1.541480 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.668204  [   32/10000]\n",
      "loss: 1.248686  [ 3232/10000]\n",
      "loss: 0.593991  [ 6432/10000]\n",
      "loss: 0.252364  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.168328 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34681.304688  [   32/10000]\n",
      "loss: 29172.572266  [ 3232/10000]\n",
      "loss: 25281.187500  [ 6432/10000]\n",
      "loss: 21255.130859  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 20874.146790 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 21673.509766  [   32/10000]\n",
      "loss: 18545.789062  [ 3232/10000]\n",
      "loss: 15079.181641  [ 6432/10000]\n",
      "loss: 12235.037109  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 12307.698517 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 12203.537109  [   32/10000]\n",
      "loss: 10055.718750  [ 3232/10000]\n",
      "loss: 8568.924805  [ 6432/10000]\n",
      "loss: 6466.399414  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6788.164612 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 7124.165039  [   32/10000]\n",
      "loss: 5342.667480  [ 3232/10000]\n",
      "loss: 4752.151367  [ 6432/10000]\n",
      "loss: 3909.129395  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3464.542923 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3407.156250  [   32/10000]\n",
      "loss: 2804.885254  [ 3232/10000]\n",
      "loss: 2169.118896  [ 6432/10000]\n",
      "loss: 1776.058716  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1627.222141 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1637.663696  [   32/10000]\n",
      "loss: 1249.853271  [ 3232/10000]\n",
      "loss: 854.173340  [ 6432/10000]\n",
      "loss: 777.500488  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 711.899981 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 694.315918  [   32/10000]\n",
      "loss: 503.101685  [ 3232/10000]\n",
      "loss: 372.071320  [ 6432/10000]\n",
      "loss: 319.272186  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 308.956625 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 280.061920  [   32/10000]\n",
      "loss: 220.345886  [ 3232/10000]\n",
      "loss: 157.030533  [ 6432/10000]\n",
      "loss: 144.278748  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 151.337454 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 153.009827  [   32/10000]\n",
      "loss: 127.794228  [ 3232/10000]\n",
      "loss: 93.772469  [ 6432/10000]\n",
      "loss: 84.109978  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 92.897398 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 92.201973  [   32/10000]\n",
      "loss: 83.878174  [ 3232/10000]\n",
      "loss: 78.671478  [ 6432/10000]\n",
      "loss: 66.052116  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 68.298571 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 68.434929  [   32/10000]\n",
      "loss: 67.341942  [ 3232/10000]\n",
      "loss: 51.593315  [ 6432/10000]\n",
      "loss: 51.308887  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 53.812776 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 50.328873  [   32/10000]\n",
      "loss: 46.233002  [ 3232/10000]\n",
      "loss: 45.367901  [ 6432/10000]\n",
      "loss: 42.631378  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 42.821796 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 39.491726  [   32/10000]\n",
      "loss: 35.531822  [ 3232/10000]\n",
      "loss: 27.451805  [ 6432/10000]\n",
      "loss: 38.431583  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 33.944380 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 32.858868  [   32/10000]\n",
      "loss: 28.727440  [ 3232/10000]\n",
      "loss: 25.347801  [ 6432/10000]\n",
      "loss: 30.433916  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 26.908684 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 24.839964  [   32/10000]\n",
      "loss: 24.704519  [ 3232/10000]\n",
      "loss: 22.711388  [ 6432/10000]\n",
      "loss: 20.300104  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 21.538926 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 20.135954  [   32/10000]\n",
      "loss: 18.011326  [ 3232/10000]\n",
      "loss: 21.376467  [ 6432/10000]\n",
      "loss: 14.322437  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 17.635835 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 14.348336  [   32/10000]\n",
      "loss: 15.812996  [ 3232/10000]\n",
      "loss: 15.011613  [ 6432/10000]\n",
      "loss: 12.688205  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.909694 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 13.794965  [   32/10000]\n",
      "loss: 12.863294  [ 3232/10000]\n",
      "loss: 12.430859  [ 6432/10000]\n",
      "loss: 13.169675  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 13.067027 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 11.506970  [   32/10000]\n",
      "loss: 13.768125  [ 3232/10000]\n",
      "loss: 14.086902  [ 6432/10000]\n",
      "loss: 10.231919  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.810439 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 11.943310  [   32/10000]\n",
      "loss: 10.376437  [ 3232/10000]\n",
      "loss: 11.205581  [ 6432/10000]\n",
      "loss: 10.529366  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.906870 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 10.731123  [   32/10000]\n",
      "loss: 9.826758  [ 3232/10000]\n",
      "loss: 10.996400  [ 6432/10000]\n",
      "loss: 11.058800  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.184191 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 8.581346  [   32/10000]\n",
      "loss: 8.999350  [ 3232/10000]\n",
      "loss: 8.475109  [ 6432/10000]\n",
      "loss: 8.537870  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.503105 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 9.279708  [   32/10000]\n",
      "loss: 8.255105  [ 3232/10000]\n",
      "loss: 9.066329  [ 6432/10000]\n",
      "loss: 7.778905  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.824320 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 7.643442  [   32/10000]\n",
      "loss: 8.710615  [ 3232/10000]\n",
      "loss: 9.370273  [ 6432/10000]\n",
      "loss: 9.472239  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.110603 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 7.755970  [   32/10000]\n",
      "loss: 6.839190  [ 3232/10000]\n",
      "loss: 7.660253  [ 6432/10000]\n",
      "loss: 7.821352  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.366630 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 7.550581  [   32/10000]\n",
      "loss: 6.526886  [ 3232/10000]\n",
      "loss: 7.284597  [ 6432/10000]\n",
      "loss: 5.504832  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6.597524 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 6.373521  [   32/10000]\n",
      "loss: 5.302680  [ 3232/10000]\n",
      "loss: 5.808373  [ 6432/10000]\n",
      "loss: 5.504004  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.777359 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.464619  [   32/10000]\n",
      "loss: 5.417204  [ 3232/10000]\n",
      "loss: 4.396031  [ 6432/10000]\n",
      "loss: 4.798961  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.965609 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4.282621  [   32/10000]\n",
      "loss: 4.162007  [ 3232/10000]\n",
      "loss: 4.668365  [ 6432/10000]\n",
      "loss: 3.360810  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.175400 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 5.021964  [   32/10000]\n",
      "loss: 3.386849  [ 3232/10000]\n",
      "loss: 3.560431  [ 6432/10000]\n",
      "loss: 3.538016  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.410669 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30649.484375  [   32/10000]\n",
      "loss: 18567.972656  [ 3232/10000]\n",
      "loss: 10971.855469  [ 6432/10000]\n",
      "loss: 6444.763672  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6017.538956 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 6022.841309  [   32/10000]\n",
      "loss: 3409.993652  [ 3232/10000]\n",
      "loss: 1982.392822  [ 6432/10000]\n",
      "loss: 1163.860107  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1156.393326 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1048.843018  [   32/10000]\n",
      "loss: 771.934692  [ 3232/10000]\n",
      "loss: 529.172791  [ 6432/10000]\n",
      "loss: 455.225037  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 438.499732 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 380.993042  [   32/10000]\n",
      "loss: 334.625671  [ 3232/10000]\n",
      "loss: 305.162659  [ 6432/10000]\n",
      "loss: 265.968231  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 282.848348 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 246.019135  [   32/10000]\n",
      "loss: 230.535004  [ 3232/10000]\n",
      "loss: 228.631149  [ 6432/10000]\n",
      "loss: 213.842377  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 210.406877 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 194.969711  [   32/10000]\n",
      "loss: 173.744278  [ 3232/10000]\n",
      "loss: 164.571014  [ 6432/10000]\n",
      "loss: 163.840256  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 161.712907 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 143.988174  [   32/10000]\n",
      "loss: 132.480072  [ 3232/10000]\n",
      "loss: 128.469604  [ 6432/10000]\n",
      "loss: 117.927338  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 123.300302 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 106.448097  [   32/10000]\n",
      "loss: 109.893440  [ 3232/10000]\n",
      "loss: 92.772629  [ 6432/10000]\n",
      "loss: 90.300758  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 92.262618 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 80.209824  [   32/10000]\n",
      "loss: 75.127502  [ 3232/10000]\n",
      "loss: 63.633495  [ 6432/10000]\n",
      "loss: 56.006504  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 67.944912 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 53.235966  [   32/10000]\n",
      "loss: 55.957798  [ 3232/10000]\n",
      "loss: 46.273540  [ 6432/10000]\n",
      "loss: 44.277611  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 49.124802 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 36.579552  [   32/10000]\n",
      "loss: 37.913700  [ 3232/10000]\n",
      "loss: 33.190361  [ 6432/10000]\n",
      "loss: 29.844017  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 35.566813 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 28.643970  [   32/10000]\n",
      "loss: 28.696026  [ 3232/10000]\n",
      "loss: 25.982290  [ 6432/10000]\n",
      "loss: 22.844769  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 26.153857 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 22.960011  [   32/10000]\n",
      "loss: 20.033325  [ 3232/10000]\n",
      "loss: 19.084341  [ 6432/10000]\n",
      "loss: 18.532171  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 19.930913 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 14.901289  [   32/10000]\n",
      "loss: 14.461975  [ 3232/10000]\n",
      "loss: 16.113922  [ 6432/10000]\n",
      "loss: 14.917964  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.906846 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 13.547812  [   32/10000]\n",
      "loss: 13.061096  [ 3232/10000]\n",
      "loss: 10.575592  [ 6432/10000]\n",
      "loss: 11.058164  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 13.377627 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 10.350339  [   32/10000]\n",
      "loss: 11.095630  [ 3232/10000]\n",
      "loss: 11.060546  [ 6432/10000]\n",
      "loss: 10.956594  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.800919 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 7.988995  [   32/10000]\n",
      "loss: 10.958788  [ 3232/10000]\n",
      "loss: 9.145090  [ 6432/10000]\n",
      "loss: 8.737584  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.701439 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 9.036987  [   32/10000]\n",
      "loss: 9.666759  [ 3232/10000]\n",
      "loss: 8.719697  [ 6432/10000]\n",
      "loss: 7.974183  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.871190 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 8.453534  [   32/10000]\n",
      "loss: 8.852272  [ 3232/10000]\n",
      "loss: 8.098486  [ 6432/10000]\n",
      "loss: 7.855217  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.173093 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 6.776004  [   32/10000]\n",
      "loss: 9.134752  [ 3232/10000]\n",
      "loss: 9.167666  [ 6432/10000]\n",
      "loss: 6.951285  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.479905 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 7.284954  [   32/10000]\n",
      "loss: 6.487298  [ 3232/10000]\n",
      "loss: 6.315691  [ 6432/10000]\n",
      "loss: 6.499122  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.778173 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 7.582829  [   32/10000]\n",
      "loss: 6.457497  [ 3232/10000]\n",
      "loss: 6.038094  [ 6432/10000]\n",
      "loss: 7.057248  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.052449 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 6.234787  [   32/10000]\n",
      "loss: 5.942119  [ 3232/10000]\n",
      "loss: 6.477203  [ 6432/10000]\n",
      "loss: 6.237871  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6.293168 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4.597658  [   32/10000]\n",
      "loss: 5.187593  [ 3232/10000]\n",
      "loss: 5.531158  [ 6432/10000]\n",
      "loss: 5.729856  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.539255 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.391188  [   32/10000]\n",
      "loss: 4.626314  [ 3232/10000]\n",
      "loss: 4.179317  [ 6432/10000]\n",
      "loss: 5.185721  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.227534 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.713804  [   32/10000]\n",
      "loss: 4.571699  [ 3232/10000]\n",
      "loss: 4.510664  [ 6432/10000]\n",
      "loss: 4.596826  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.702111 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.519907  [   32/10000]\n",
      "loss: 4.060169  [ 3232/10000]\n",
      "loss: 4.839929  [ 6432/10000]\n",
      "loss: 4.428409  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.594449 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.004475  [   32/10000]\n",
      "loss: 4.058973  [ 3232/10000]\n",
      "loss: 3.917909  [ 6432/10000]\n",
      "loss: 3.578897  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.612068 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.292191  [   32/10000]\n",
      "loss: 2.811099  [ 3232/10000]\n",
      "loss: 2.915620  [ 6432/10000]\n",
      "loss: 2.425958  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.574403 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.249996  [   32/10000]\n",
      "loss: 2.255160  [ 3232/10000]\n",
      "loss: 2.358497  [ 6432/10000]\n",
      "loss: 2.092527  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.152704 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31425.964844  [   32/10000]\n",
      "loss: 19882.083984  [ 3232/10000]\n",
      "loss: 6724.016113  [ 6432/10000]\n",
      "loss: 5192.076660  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5232.048309 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5147.127441  [   32/10000]\n",
      "loss: 5104.339844  [ 3232/10000]\n",
      "loss: 5051.876465  [ 6432/10000]\n",
      "loss: 5030.023438  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5042.770828 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5041.311523  [   32/10000]\n",
      "loss: 4824.669434  [ 3232/10000]\n",
      "loss: 4854.748047  [ 6432/10000]\n",
      "loss: 4815.843750  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4711.955902 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4512.221191  [   32/10000]\n",
      "loss: 4402.765625  [ 3232/10000]\n",
      "loss: 4336.660156  [ 6432/10000]\n",
      "loss: 4091.823242  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3929.931641 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3922.721191  [   32/10000]\n",
      "loss: 3599.879883  [ 3232/10000]\n",
      "loss: 3111.996826  [ 6432/10000]\n",
      "loss: 2690.936035  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2584.764191 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2446.245117  [   32/10000]\n",
      "loss: 2016.796143  [ 3232/10000]\n",
      "loss: 1644.327759  [ 6432/10000]\n",
      "loss: 1277.272339  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1188.547600 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1215.074951  [   32/10000]\n",
      "loss: 824.671875  [ 3232/10000]\n",
      "loss: 542.029968  [ 6432/10000]\n",
      "loss: 349.549652  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 336.519489 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 343.966431  [   32/10000]\n",
      "loss: 197.791138  [ 3232/10000]\n",
      "loss: 104.912346  [ 6432/10000]\n",
      "loss: 57.181435  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 51.962093 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 51.803558  [   32/10000]\n",
      "loss: 25.030699  [ 3232/10000]\n",
      "loss: 12.370395  [ 6432/10000]\n",
      "loss: 5.851015  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.264678 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 5.253543  [   32/10000]\n",
      "loss: 2.455010  [ 3232/10000]\n",
      "loss: 1.046870  [ 6432/10000]\n",
      "loss: 0.463271  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.410424 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.391364  [   32/10000]\n",
      "loss: 0.165807  [ 3232/10000]\n",
      "loss: 0.069651  [ 6432/10000]\n",
      "loss: 0.025361  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.024237 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.024606  [   32/10000]\n",
      "loss: 0.008692  [ 3232/10000]\n",
      "loss: 0.003022  [ 6432/10000]\n",
      "loss: 0.001204  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.001018 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.001021  [   32/10000]\n",
      "loss: 0.000349  [ 3232/10000]\n",
      "loss: 0.000107  [ 6432/10000]\n",
      "loss: 0.000032  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000028 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/10000]\n",
      "loss: 0.000007  [ 3232/10000]\n",
      "loss: 0.000002  [ 6432/10000]\n",
      "loss: 0.000001  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31178.980469  [   32/10000]\n",
      "loss: 2793.355957  [ 3232/10000]\n",
      "loss: 2669.805664  [ 6432/10000]\n",
      "loss: 2662.062744  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2626.584442 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2672.571045  [   32/10000]\n",
      "loss: 2480.424805  [ 3232/10000]\n",
      "loss: 2389.548584  [ 6432/10000]\n",
      "loss: 2466.409424  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2478.284279 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2489.565186  [   32/10000]\n",
      "loss: 2295.397705  [ 3232/10000]\n",
      "loss: 2244.658203  [ 6432/10000]\n",
      "loss: 2300.011230  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2310.476440 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2228.389648  [   32/10000]\n",
      "loss: 2181.320068  [ 3232/10000]\n",
      "loss: 2196.158203  [ 6432/10000]\n",
      "loss: 2196.418701  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2128.318932 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2153.805420  [   32/10000]\n",
      "loss: 2106.232910  [ 3232/10000]\n",
      "loss: 1915.771973  [ 6432/10000]\n",
      "loss: 2028.861450  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1960.632656 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1900.155640  [   32/10000]\n",
      "loss: 1865.197144  [ 3232/10000]\n",
      "loss: 1825.590210  [ 6432/10000]\n",
      "loss: 1821.074097  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1830.208866 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1808.197998  [   32/10000]\n",
      "loss: 1745.368652  [ 3232/10000]\n",
      "loss: 1759.512451  [ 6432/10000]\n",
      "loss: 1675.808594  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1735.436951 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1677.721069  [   32/10000]\n",
      "loss: 1683.174316  [ 3232/10000]\n",
      "loss: 1618.130737  [ 6432/10000]\n",
      "loss: 1575.167603  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1668.061512 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1602.118164  [   32/10000]\n",
      "loss: 1614.816040  [ 3232/10000]\n",
      "loss: 1541.203735  [ 6432/10000]\n",
      "loss: 1585.911743  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1619.766914 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1563.292603  [   32/10000]\n",
      "loss: 1587.019531  [ 3232/10000]\n",
      "loss: 1610.285522  [ 6432/10000]\n",
      "loss: 1516.583008  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1581.766647 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1575.519165  [   32/10000]\n",
      "loss: 1510.321411  [ 3232/10000]\n",
      "loss: 1552.617920  [ 6432/10000]\n",
      "loss: 1507.246094  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1557.329971 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1510.979492  [   32/10000]\n",
      "loss: 1493.141235  [ 3232/10000]\n",
      "loss: 1483.093384  [ 6432/10000]\n",
      "loss: 1496.862549  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1532.346378 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1476.468750  [   32/10000]\n",
      "loss: 1477.322510  [ 3232/10000]\n",
      "loss: 1464.411255  [ 6432/10000]\n",
      "loss: 1523.465942  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1518.872688 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1434.803711  [   32/10000]\n",
      "loss: 1488.194946  [ 3232/10000]\n",
      "loss: 1516.676392  [ 6432/10000]\n",
      "loss: 1461.279053  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1499.307098 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1479.984741  [   32/10000]\n",
      "loss: 1395.874634  [ 3232/10000]\n",
      "loss: 1433.732178  [ 6432/10000]\n",
      "loss: 1418.557373  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1489.656784 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1408.161255  [   32/10000]\n",
      "loss: 1368.721924  [ 3232/10000]\n",
      "loss: 1473.700195  [ 6432/10000]\n",
      "loss: 1385.972778  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1480.564724 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1498.352539  [   32/10000]\n",
      "loss: 1512.484253  [ 3232/10000]\n",
      "loss: 1412.432861  [ 6432/10000]\n",
      "loss: 1461.808228  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1479.612293 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1439.943481  [   32/10000]\n",
      "loss: 1480.255127  [ 3232/10000]\n",
      "loss: 1441.121582  [ 6432/10000]\n",
      "loss: 1457.990356  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1473.205231 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1485.472290  [   32/10000]\n",
      "loss: 1421.585327  [ 3232/10000]\n",
      "loss: 1518.208496  [ 6432/10000]\n",
      "loss: 1464.002808  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1465.637402 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1455.923096  [   32/10000]\n",
      "loss: 1417.799805  [ 3232/10000]\n",
      "loss: 1395.044434  [ 6432/10000]\n",
      "loss: 1477.605957  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1465.159645 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1430.946411  [   32/10000]\n",
      "loss: 1369.820801  [ 3232/10000]\n",
      "loss: 1465.653076  [ 6432/10000]\n",
      "loss: 1426.687866  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1465.611969 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1425.623413  [   32/10000]\n",
      "loss: 1441.128296  [ 3232/10000]\n",
      "loss: 1453.295044  [ 6432/10000]\n",
      "loss: 1455.460205  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1462.353573 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1438.395508  [   32/10000]\n",
      "loss: 1456.067505  [ 3232/10000]\n",
      "loss: 1456.990112  [ 6432/10000]\n",
      "loss: 1441.821045  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1459.317436 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1387.468628  [   32/10000]\n",
      "loss: 1370.071289  [ 3232/10000]\n",
      "loss: 1388.634277  [ 6432/10000]\n",
      "loss: 1459.935059  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1461.300735 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1434.454346  [   32/10000]\n",
      "loss: 1376.034058  [ 3232/10000]\n",
      "loss: 1419.606689  [ 6432/10000]\n",
      "loss: 1387.822754  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1455.304966 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1417.293091  [   32/10000]\n",
      "loss: 1391.144165  [ 3232/10000]\n",
      "loss: 1423.447754  [ 6432/10000]\n",
      "loss: 1443.843384  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1456.208183 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1350.141602  [   32/10000]\n",
      "loss: 1353.874023  [ 3232/10000]\n",
      "loss: 1443.449829  [ 6432/10000]\n",
      "loss: 1429.463745  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1455.822746 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1385.473267  [   32/10000]\n",
      "loss: 1404.731079  [ 3232/10000]\n",
      "loss: 1426.661255  [ 6432/10000]\n",
      "loss: 1406.931763  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1455.840988 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1470.269043  [   32/10000]\n",
      "loss: 1437.249878  [ 3232/10000]\n",
      "loss: 1450.133301  [ 6432/10000]\n",
      "loss: 1414.462646  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1457.617668 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1424.054077  [   32/10000]\n",
      "loss: 1449.918701  [ 3232/10000]\n",
      "loss: 1404.281982  [ 6432/10000]\n",
      "loss: 1379.608765  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1451.752533 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30222.937500  [   32/10000]\n",
      "loss: 18229.773438  [ 3232/10000]\n",
      "loss: 10986.365234  [ 6432/10000]\n",
      "loss: 6409.274414  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6049.115906 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 6104.878906  [   32/10000]\n",
      "loss: 3359.516357  [ 3232/10000]\n",
      "loss: 1861.417847  [ 6432/10000]\n",
      "loss: 1239.991455  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1160.505955 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1158.335815  [   32/10000]\n",
      "loss: 743.884583  [ 3232/10000]\n",
      "loss: 507.575867  [ 6432/10000]\n",
      "loss: 411.127350  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 437.415751 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 388.533112  [   32/10000]\n",
      "loss: 330.845795  [ 3232/10000]\n",
      "loss: 292.768677  [ 6432/10000]\n",
      "loss: 281.971985  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 281.978042 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 269.739655  [   32/10000]\n",
      "loss: 229.507446  [ 3232/10000]\n",
      "loss: 206.306076  [ 6432/10000]\n",
      "loss: 199.826508  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 210.089528 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 179.747910  [   32/10000]\n",
      "loss: 180.440857  [ 3232/10000]\n",
      "loss: 174.545593  [ 6432/10000]\n",
      "loss: 138.768021  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 161.397385 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 138.388275  [   32/10000]\n",
      "loss: 127.285851  [ 3232/10000]\n",
      "loss: 123.349510  [ 6432/10000]\n",
      "loss: 122.774025  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 123.408130 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 103.274246  [   32/10000]\n",
      "loss: 107.307480  [ 3232/10000]\n",
      "loss: 91.105858  [ 6432/10000]\n",
      "loss: 79.235321  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 92.339834 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 74.139694  [   32/10000]\n",
      "loss: 71.758797  [ 3232/10000]\n",
      "loss: 72.192406  [ 6432/10000]\n",
      "loss: 67.640411  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 67.837601 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 60.876568  [   32/10000]\n",
      "loss: 51.132801  [ 3232/10000]\n",
      "loss: 46.083950  [ 6432/10000]\n",
      "loss: 45.975708  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 49.180398 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 42.854759  [   32/10000]\n",
      "loss: 41.837032  [ 3232/10000]\n",
      "loss: 37.281414  [ 6432/10000]\n",
      "loss: 32.233608  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 35.597648 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 32.720322  [   32/10000]\n",
      "loss: 25.224661  [ 3232/10000]\n",
      "loss: 26.127287  [ 6432/10000]\n",
      "loss: 24.387259  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 26.175953 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 19.842779  [   32/10000]\n",
      "loss: 19.383766  [ 3232/10000]\n",
      "loss: 18.834883  [ 6432/10000]\n",
      "loss: 16.129299  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 19.912435 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 14.364998  [   32/10000]\n",
      "loss: 17.997835  [ 3232/10000]\n",
      "loss: 13.759753  [ 6432/10000]\n",
      "loss: 14.136061  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.910083 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 15.353097  [   32/10000]\n",
      "loss: 12.090223  [ 3232/10000]\n",
      "loss: 12.769428  [ 6432/10000]\n",
      "loss: 11.729731  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 13.404782 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 10.509346  [   32/10000]\n",
      "loss: 10.632627  [ 3232/10000]\n",
      "loss: 9.188985  [ 6432/10000]\n",
      "loss: 9.756573  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 11.800509 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 11.086013  [   32/10000]\n",
      "loss: 9.556829  [ 3232/10000]\n",
      "loss: 11.088552  [ 6432/10000]\n",
      "loss: 9.260638  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 10.736432 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 8.995912  [   32/10000]\n",
      "loss: 8.701042  [ 3232/10000]\n",
      "loss: 7.966769  [ 6432/10000]\n",
      "loss: 8.718816  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.910206 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 8.671869  [   32/10000]\n",
      "loss: 8.121398  [ 3232/10000]\n",
      "loss: 8.474401  [ 6432/10000]\n",
      "loss: 8.106508  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 9.208873 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 8.051993  [   32/10000]\n",
      "loss: 7.303199  [ 3232/10000]\n",
      "loss: 8.047925  [ 6432/10000]\n",
      "loss: 6.839857  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8.505314 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 7.668526  [   32/10000]\n",
      "loss: 7.047302  [ 3232/10000]\n",
      "loss: 7.343828  [ 6432/10000]\n",
      "loss: 7.426054  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.795209 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 6.731870  [   32/10000]\n",
      "loss: 6.584519  [ 3232/10000]\n",
      "loss: 6.878440  [ 6432/10000]\n",
      "loss: 6.668183  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.102641 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 5.345840  [   32/10000]\n",
      "loss: 5.713098  [ 3232/10000]\n",
      "loss: 5.919720  [ 6432/10000]\n",
      "loss: 6.391897  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6.330467 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 5.515764  [   32/10000]\n",
      "loss: 5.210021  [ 3232/10000]\n",
      "loss: 5.078971  [ 6432/10000]\n",
      "loss: 5.093903  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.558414 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.571436  [   32/10000]\n",
      "loss: 5.221452  [ 3232/10000]\n",
      "loss: 4.307631  [ 6432/10000]\n",
      "loss: 4.495510  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 5.108859 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.462967  [   32/10000]\n",
      "loss: 4.705357  [ 3232/10000]\n",
      "loss: 4.508048  [ 6432/10000]\n",
      "loss: 5.032248  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.810161 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.109832  [   32/10000]\n",
      "loss: 3.872201  [ 3232/10000]\n",
      "loss: 4.740822  [ 6432/10000]\n",
      "loss: 4.363618  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4.556437 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.091174  [   32/10000]\n",
      "loss: 3.884847  [ 3232/10000]\n",
      "loss: 3.640201  [ 6432/10000]\n",
      "loss: 3.605311  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3.868261 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.251709  [   32/10000]\n",
      "loss: 2.922473  [ 3232/10000]\n",
      "loss: 2.869950  [ 6432/10000]\n",
      "loss: 2.350763  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.572330 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.162585  [   32/10000]\n",
      "loss: 2.263058  [ 3232/10000]\n",
      "loss: 2.140279  [ 6432/10000]\n",
      "loss: 2.111361  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2.143117 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 166182.296875  [   32/10000]\n",
      "loss: 132668.234375  [ 3232/10000]\n",
      "loss: 109764.179688  [ 6432/10000]\n",
      "loss: 89809.007812  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 88399.442383 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 88000.921875  [   32/10000]\n",
      "loss: 71018.468750  [ 3232/10000]\n",
      "loss: 58300.691406  [ 6432/10000]\n",
      "loss: 43987.425781  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 43540.052490 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 42220.730469  [   32/10000]\n",
      "loss: 33052.421875  [ 3232/10000]\n",
      "loss: 26166.062500  [ 6432/10000]\n",
      "loss: 19751.035156  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 19022.505737 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 18615.566406  [   32/10000]\n",
      "loss: 13966.747070  [ 3232/10000]\n",
      "loss: 10271.838867  [ 6432/10000]\n",
      "loss: 7107.221191  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7289.415817 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 7049.327637  [   32/10000]\n",
      "loss: 5119.998535  [ 3232/10000]\n",
      "loss: 3573.919434  [ 6432/10000]\n",
      "loss: 2380.388672  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2529.946266 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2371.935791  [   32/10000]\n",
      "loss: 1673.427856  [ 3232/10000]\n",
      "loss: 1207.481812  [ 6432/10000]\n",
      "loss: 872.286377  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 937.226936 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 893.950623  [   32/10000]\n",
      "loss: 652.460327  [ 3232/10000]\n",
      "loss: 525.549194  [ 6432/10000]\n",
      "loss: 430.989624  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 489.526806 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 423.087433  [   32/10000]\n",
      "loss: 366.135834  [ 3232/10000]\n",
      "loss: 353.468903  [ 6432/10000]\n",
      "loss: 335.267487  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 363.404720 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 350.228058  [   32/10000]\n",
      "loss: 318.292786  [ 3232/10000]\n",
      "loss: 308.816101  [ 6432/10000]\n",
      "loss: 284.141724  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 308.174174 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 306.643066  [   32/10000]\n",
      "loss: 269.746307  [ 3232/10000]\n",
      "loss: 269.159576  [ 6432/10000]\n",
      "loss: 248.681442  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 266.515516 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 260.331085  [   32/10000]\n",
      "loss: 245.797806  [ 3232/10000]\n",
      "loss: 227.774628  [ 6432/10000]\n",
      "loss: 227.238907  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 228.674067 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 209.025192  [   32/10000]\n",
      "loss: 213.173889  [ 3232/10000]\n",
      "loss: 204.693512  [ 6432/10000]\n",
      "loss: 174.021194  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 193.785366 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 178.908279  [   32/10000]\n",
      "loss: 174.439087  [ 3232/10000]\n",
      "loss: 152.699280  [ 6432/10000]\n",
      "loss: 145.786392  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 162.013296 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 140.623520  [   32/10000]\n",
      "loss: 137.984177  [ 3232/10000]\n",
      "loss: 135.936829  [ 6432/10000]\n",
      "loss: 114.690872  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 133.346745 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 113.601143  [   32/10000]\n",
      "loss: 104.997513  [ 3232/10000]\n",
      "loss: 112.318390  [ 6432/10000]\n",
      "loss: 97.384659  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 108.212535 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 88.425743  [   32/10000]\n",
      "loss: 83.406700  [ 3232/10000]\n",
      "loss: 88.258484  [ 6432/10000]\n",
      "loss: 77.398438  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 86.583631 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 78.115730  [   32/10000]\n",
      "loss: 71.546753  [ 3232/10000]\n",
      "loss: 64.299385  [ 6432/10000]\n",
      "loss: 57.804649  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 68.628743 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 65.506355  [   32/10000]\n",
      "loss: 57.828415  [ 3232/10000]\n",
      "loss: 58.665215  [ 6432/10000]\n",
      "loss: 45.848873  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 54.008787 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 44.399502  [   32/10000]\n",
      "loss: 42.970360  [ 3232/10000]\n",
      "loss: 40.164711  [ 6432/10000]\n",
      "loss: 40.991478  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 42.683399 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 35.701405  [   32/10000]\n",
      "loss: 30.158308  [ 3232/10000]\n",
      "loss: 33.764969  [ 6432/10000]\n",
      "loss: 29.470535  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 34.193841 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 27.787714  [   32/10000]\n",
      "loss: 26.531590  [ 3232/10000]\n",
      "loss: 25.660208  [ 6432/10000]\n",
      "loss: 24.911598  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 28.075863 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 22.689560  [   32/10000]\n",
      "loss: 24.361387  [ 3232/10000]\n",
      "loss: 21.128290  [ 6432/10000]\n",
      "loss: 21.430853  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 23.805245 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 20.386497  [   32/10000]\n",
      "loss: 19.473797  [ 3232/10000]\n",
      "loss: 16.555239  [ 6432/10000]\n",
      "loss: 18.440918  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 20.913684 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 16.500441  [   32/10000]\n",
      "loss: 19.748325  [ 3232/10000]\n",
      "loss: 16.553461  [ 6432/10000]\n",
      "loss: 16.152328  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 18.971927 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 15.232246  [   32/10000]\n",
      "loss: 16.201649  [ 3232/10000]\n",
      "loss: 16.823257  [ 6432/10000]\n",
      "loss: 18.009007  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 17.612312 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 15.498571  [   32/10000]\n",
      "loss: 15.164132  [ 3232/10000]\n",
      "loss: 15.927020  [ 6432/10000]\n",
      "loss: 15.417218  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 16.541684 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 14.545252  [   32/10000]\n",
      "loss: 13.547190  [ 3232/10000]\n",
      "loss: 12.938580  [ 6432/10000]\n",
      "loss: 13.836876  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.632301 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 11.945731  [   32/10000]\n",
      "loss: 15.073556  [ 3232/10000]\n",
      "loss: 12.669210  [ 6432/10000]\n",
      "loss: 14.585688  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.833426 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 11.165833  [   32/10000]\n",
      "loss: 13.121082  [ 3232/10000]\n",
      "loss: 12.735692  [ 6432/10000]\n",
      "loss: 14.021709  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.072604 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 12.203801  [   32/10000]\n",
      "loss: 13.536208  [ 3232/10000]\n",
      "loss: 14.114293  [ 6432/10000]\n",
      "loss: 15.208202  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.115099 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 164496.250000  [   32/10000]\n",
      "loss: 73009.648438  [ 3232/10000]\n",
      "loss: 9088.914062  [ 6432/10000]\n",
      "loss: 7926.302734  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 8223.621872 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 8257.099609  [   32/10000]\n",
      "loss: 8175.912109  [ 3232/10000]\n",
      "loss: 7705.458008  [ 6432/10000]\n",
      "loss: 7926.781250  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7928.318298 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 7880.671387  [   32/10000]\n",
      "loss: 7656.131348  [ 3232/10000]\n",
      "loss: 7572.548828  [ 6432/10000]\n",
      "loss: 7679.897461  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7510.381760 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 7082.524902  [   32/10000]\n",
      "loss: 7229.168945  [ 3232/10000]\n",
      "loss: 7113.917480  [ 6432/10000]\n",
      "loss: 6985.560059  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6906.029327 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 6997.852051  [   32/10000]\n",
      "loss: 6569.876465  [ 3232/10000]\n",
      "loss: 6060.600098  [ 6432/10000]\n",
      "loss: 6011.390137  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 6057.883514 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 5930.631836  [   32/10000]\n",
      "loss: 5518.802734  [ 3232/10000]\n",
      "loss: 5341.243164  [ 6432/10000]\n",
      "loss: 5147.674805  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4982.390991 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4776.280273  [   32/10000]\n",
      "loss: 4375.087891  [ 3232/10000]\n",
      "loss: 4221.690918  [ 6432/10000]\n",
      "loss: 3745.099365  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3822.817108 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3880.257568  [   32/10000]\n",
      "loss: 3403.913818  [ 3232/10000]\n",
      "loss: 3090.481445  [ 6432/10000]\n",
      "loss: 2749.871582  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2751.943306 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2823.632080  [   32/10000]\n",
      "loss: 2481.272705  [ 3232/10000]\n",
      "loss: 2111.904541  [ 6432/10000]\n",
      "loss: 1883.768433  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1852.183090 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1763.454956  [   32/10000]\n",
      "loss: 1619.205322  [ 3232/10000]\n",
      "loss: 1342.048096  [ 6432/10000]\n",
      "loss: 1145.933716  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1154.496517 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1134.178955  [   32/10000]\n",
      "loss: 960.144836  [ 3232/10000]\n",
      "loss: 783.743652  [ 6432/10000]\n",
      "loss: 671.255615  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 661.750940 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 639.162415  [   32/10000]\n",
      "loss: 540.571411  [ 3232/10000]\n",
      "loss: 448.104950  [ 6432/10000]\n",
      "loss: 354.191498  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 349.884370 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 333.946106  [   32/10000]\n",
      "loss: 269.493683  [ 3232/10000]\n",
      "loss: 199.108734  [ 6432/10000]\n",
      "loss: 173.937775  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 167.002656 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 163.014511  [   32/10000]\n",
      "loss: 125.615906  [ 3232/10000]\n",
      "loss: 86.823799  [ 6432/10000]\n",
      "loss: 56.513866  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 53.752322 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 55.670982  [   32/10000]\n",
      "loss: 29.452587  [ 3232/10000]\n",
      "loss: 15.832023  [ 6432/10000]\n",
      "loss: 7.934963  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7.495110 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 7.058008  [   32/10000]\n",
      "loss: 3.394629  [ 3232/10000]\n",
      "loss: 1.729128  [ 6432/10000]\n",
      "loss: 0.771196  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.705359 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.666088  [   32/10000]\n",
      "loss: 0.317027  [ 3232/10000]\n",
      "loss: 0.141041  [ 6432/10000]\n",
      "loss: 0.057090  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.053789 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.052550  [   32/10000]\n",
      "loss: 0.021429  [ 3232/10000]\n",
      "loss: 0.008858  [ 6432/10000]\n",
      "loss: 0.003290  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.003070 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.002819  [   32/10000]\n",
      "loss: 0.001141  [ 3232/10000]\n",
      "loss: 0.000381  [ 6432/10000]\n",
      "loss: 0.000134  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000119 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000110  [   32/10000]\n",
      "loss: 0.000039  [ 3232/10000]\n",
      "loss: 0.000012  [ 6432/10000]\n",
      "loss: 0.000003  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000003 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000003  [   32/10000]\n",
      "loss: 0.000001  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000000  [   32/10000]\n",
      "loss: 0.000000  [ 3232/10000]\n",
      "loss: 0.000000  [ 6432/10000]\n",
      "loss: 0.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 0.000000 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 166090.875000  [   32/10000]\n",
      "loss: 4508.317383  [ 3232/10000]\n",
      "loss: 4375.485352  [ 6432/10000]\n",
      "loss: 4304.823730  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 4192.600136 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4203.404785  [   32/10000]\n",
      "loss: 4112.000977  [ 3232/10000]\n",
      "loss: 4033.252441  [ 6432/10000]\n",
      "loss: 3836.614990  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3865.259171 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3777.832520  [   32/10000]\n",
      "loss: 3644.946533  [ 3232/10000]\n",
      "loss: 3418.702148  [ 6432/10000]\n",
      "loss: 3533.885010  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 3334.332100 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3281.659912  [   32/10000]\n",
      "loss: 3281.117432  [ 3232/10000]\n",
      "loss: 2749.460693  [ 6432/10000]\n",
      "loss: 2635.000000  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2584.484619 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2390.505859  [   32/10000]\n",
      "loss: 2176.694580  [ 3232/10000]\n",
      "loss: 2005.582520  [ 6432/10000]\n",
      "loss: 1828.606201  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1869.569656 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1732.897705  [   32/10000]\n",
      "loss: 1562.652832  [ 3232/10000]\n",
      "loss: 1413.319336  [ 6432/10000]\n",
      "loss: 1263.564819  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 1312.438351 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1175.675659  [   32/10000]\n",
      "loss: 1097.208862  [ 3232/10000]\n",
      "loss: 965.710449  [ 6432/10000]\n",
      "loss: 882.429688  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 920.926004 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 800.105225  [   32/10000]\n",
      "loss: 769.615601  [ 3232/10000]\n",
      "loss: 667.398926  [ 6432/10000]\n",
      "loss: 641.261108  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 668.915056 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 612.376953  [   32/10000]\n",
      "loss: 552.543640  [ 3232/10000]\n",
      "loss: 543.884277  [ 6432/10000]\n",
      "loss: 465.044067  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 506.980099 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 435.576904  [   32/10000]\n",
      "loss: 395.936829  [ 3232/10000]\n",
      "loss: 385.244934  [ 6432/10000]\n",
      "loss: 363.169189  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 386.787902 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 334.727997  [   32/10000]\n",
      "loss: 311.237183  [ 3232/10000]\n",
      "loss: 308.688019  [ 6432/10000]\n",
      "loss: 276.839172  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 298.802902 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 272.800201  [   32/10000]\n",
      "loss: 260.106995  [ 3232/10000]\n",
      "loss: 235.743668  [ 6432/10000]\n",
      "loss: 218.048523  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 242.877304 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 215.829468  [   32/10000]\n",
      "loss: 217.507889  [ 3232/10000]\n",
      "loss: 202.054565  [ 6432/10000]\n",
      "loss: 183.804382  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 201.034025 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 176.845749  [   32/10000]\n",
      "loss: 170.261383  [ 3232/10000]\n",
      "loss: 182.253082  [ 6432/10000]\n",
      "loss: 168.628357  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 176.156590 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 153.755081  [   32/10000]\n",
      "loss: 146.893829  [ 3232/10000]\n",
      "loss: 140.454330  [ 6432/10000]\n",
      "loss: 149.740921  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 150.750771 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 131.089722  [   32/10000]\n",
      "loss: 137.619354  [ 3232/10000]\n",
      "loss: 137.173325  [ 6432/10000]\n",
      "loss: 132.758728  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 129.599949 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 121.057381  [   32/10000]\n",
      "loss: 107.799171  [ 3232/10000]\n",
      "loss: 119.393967  [ 6432/10000]\n",
      "loss: 103.875130  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 113.086805 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 93.997429  [   32/10000]\n",
      "loss: 94.001396  [ 3232/10000]\n",
      "loss: 107.067802  [ 6432/10000]\n",
      "loss: 129.493454  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 134.170596 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 127.858788  [   32/10000]\n",
      "loss: 118.231369  [ 3232/10000]\n",
      "loss: 90.622757  [ 6432/10000]\n",
      "loss: 102.493996  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 102.834584 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 98.567627  [   32/10000]\n",
      "loss: 75.732620  [ 3232/10000]\n",
      "loss: 81.595222  [ 6432/10000]\n",
      "loss: 79.231537  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 81.368213 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 77.365891  [   32/10000]\n",
      "loss: 75.587486  [ 3232/10000]\n",
      "loss: 77.581940  [ 6432/10000]\n",
      "loss: 90.149139  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 88.928194 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 82.582520  [   32/10000]\n",
      "loss: 89.273575  [ 3232/10000]\n",
      "loss: 89.460007  [ 6432/10000]\n",
      "loss: 77.922684  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 89.737034 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 81.139542  [   32/10000]\n",
      "loss: 85.950851  [ 3232/10000]\n",
      "loss: 67.828186  [ 6432/10000]\n",
      "loss: 63.592030  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 84.246658 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 74.623383  [   32/10000]\n",
      "loss: 73.913734  [ 3232/10000]\n",
      "loss: 84.273438  [ 6432/10000]\n",
      "loss: 85.852219  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 79.628277 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 77.719025  [   32/10000]\n",
      "loss: 70.026848  [ 3232/10000]\n",
      "loss: 62.222206  [ 6432/10000]\n",
      "loss: 74.178246  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 89.729443 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 90.458603  [   32/10000]\n",
      "loss: 75.971619  [ 3232/10000]\n",
      "loss: 82.398407  [ 6432/10000]\n",
      "loss: 90.192734  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 77.799356 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 75.466881  [   32/10000]\n",
      "loss: 82.986496  [ 3232/10000]\n",
      "loss: 73.967926  [ 6432/10000]\n",
      "loss: 62.246811  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 74.118637 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 60.872974  [   32/10000]\n",
      "loss: 66.209061  [ 3232/10000]\n",
      "loss: 67.348465  [ 6432/10000]\n",
      "loss: 79.515976  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 88.621488 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 81.371857  [   32/10000]\n",
      "loss: 77.389290  [ 3232/10000]\n",
      "loss: 65.115349  [ 6432/10000]\n",
      "loss: 77.878464  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 82.675036 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 76.120094  [   32/10000]\n",
      "loss: 74.344597  [ 3232/10000]\n",
      "loss: 68.523300  [ 6432/10000]\n",
      "loss: 66.788254  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 73.225086 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 164073.609375  [   32/10000]\n",
      "loss: 135503.406250  [ 3232/10000]\n",
      "loss: 111221.679688  [ 6432/10000]\n",
      "loss: 89839.906250  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 88300.934814 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 86696.757812  [   32/10000]\n",
      "loss: 70273.992188  [ 3232/10000]\n",
      "loss: 56449.769531  [ 6432/10000]\n",
      "loss: 45280.941406  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 43463.740967 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 44155.386719  [   32/10000]\n",
      "loss: 33139.550781  [ 3232/10000]\n",
      "loss: 26233.822266  [ 6432/10000]\n",
      "loss: 19757.904297  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 18988.123535 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 18260.476562  [   32/10000]\n",
      "loss: 13899.320312  [ 3232/10000]\n",
      "loss: 10381.882812  [ 6432/10000]\n",
      "loss: 7241.834473  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 7271.216919 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 7171.154785  [   32/10000]\n",
      "loss: 5075.144043  [ 3232/10000]\n",
      "loss: 3527.178467  [ 6432/10000]\n",
      "loss: 2509.763672  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 2523.921295 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2320.561279  [   32/10000]\n",
      "loss: 1594.783691  [ 3232/10000]\n",
      "loss: 1243.828247  [ 6432/10000]\n",
      "loss: 848.594360  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 935.139261 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 833.705322  [   32/10000]\n",
      "loss: 696.829529  [ 3232/10000]\n",
      "loss: 558.951660  [ 6432/10000]\n",
      "loss: 459.947632  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 488.732369 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 468.161530  [   32/10000]\n",
      "loss: 408.988678  [ 3232/10000]\n",
      "loss: 335.756653  [ 6432/10000]\n",
      "loss: 313.490143  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 363.194283 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 343.698669  [   32/10000]\n",
      "loss: 313.225403  [ 3232/10000]\n",
      "loss: 293.558990  [ 6432/10000]\n",
      "loss: 279.219360  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 307.719258 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 279.339966  [   32/10000]\n",
      "loss: 275.549133  [ 3232/10000]\n",
      "loss: 290.469635  [ 6432/10000]\n",
      "loss: 240.526672  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 265.874728 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 228.725662  [   32/10000]\n",
      "loss: 228.759964  [ 3232/10000]\n",
      "loss: 218.869202  [ 6432/10000]\n",
      "loss: 217.701111  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 228.307515 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 205.208237  [   32/10000]\n",
      "loss: 183.844879  [ 3232/10000]\n",
      "loss: 196.252090  [ 6432/10000]\n",
      "loss: 174.879654  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 193.445065 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 181.447388  [   32/10000]\n",
      "loss: 162.717346  [ 3232/10000]\n",
      "loss: 156.052170  [ 6432/10000]\n",
      "loss: 154.247574  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 161.714232 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 147.605453  [   32/10000]\n",
      "loss: 135.031891  [ 3232/10000]\n",
      "loss: 124.114677  [ 6432/10000]\n",
      "loss: 127.511475  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 133.020982 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 118.371002  [   32/10000]\n",
      "loss: 117.524261  [ 3232/10000]\n",
      "loss: 95.676956  [ 6432/10000]\n",
      "loss: 98.082932  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 107.971532 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 99.772881  [   32/10000]\n",
      "loss: 88.601219  [ 3232/10000]\n",
      "loss: 74.707542  [ 6432/10000]\n",
      "loss: 75.019012  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 86.411719 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 71.333778  [   32/10000]\n",
      "loss: 73.901237  [ 3232/10000]\n",
      "loss: 68.871056  [ 6432/10000]\n",
      "loss: 60.533321  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 68.446740 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 60.639515  [   32/10000]\n",
      "loss: 48.646297  [ 3232/10000]\n",
      "loss: 60.015934  [ 6432/10000]\n",
      "loss: 45.105797  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 53.859297 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 44.124012  [   32/10000]\n",
      "loss: 43.338120  [ 3232/10000]\n",
      "loss: 39.940639  [ 6432/10000]\n",
      "loss: 38.046280  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 42.599728 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 38.816647  [   32/10000]\n",
      "loss: 32.427841  [ 3232/10000]\n",
      "loss: 30.251785  [ 6432/10000]\n",
      "loss: 32.989601  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 34.129317 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 28.008551  [   32/10000]\n",
      "loss: 27.610796  [ 3232/10000]\n",
      "loss: 26.021458  [ 6432/10000]\n",
      "loss: 23.779419  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 28.033679 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 24.370630  [   32/10000]\n",
      "loss: 23.673409  [ 3232/10000]\n",
      "loss: 21.173864  [ 6432/10000]\n",
      "loss: 20.213804  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 23.779379 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 18.859669  [   32/10000]\n",
      "loss: 18.405010  [ 3232/10000]\n",
      "loss: 19.104733  [ 6432/10000]\n",
      "loss: 16.390514  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 20.905063 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 17.933783  [   32/10000]\n",
      "loss: 15.974993  [ 3232/10000]\n",
      "loss: 16.865192  [ 6432/10000]\n",
      "loss: 18.633806  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 18.951406 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 15.337678  [   32/10000]\n",
      "loss: 16.162897  [ 3232/10000]\n",
      "loss: 14.630235  [ 6432/10000]\n",
      "loss: 14.924861  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 17.580921 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 14.106423  [   32/10000]\n",
      "loss: 15.146118  [ 3232/10000]\n",
      "loss: 15.217351  [ 6432/10000]\n",
      "loss: 16.032904  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 16.499151 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 13.462037  [   32/10000]\n",
      "loss: 15.431030  [ 3232/10000]\n",
      "loss: 14.591702  [ 6432/10000]\n",
      "loss: 14.757954  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.611380 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 14.997432  [   32/10000]\n",
      "loss: 14.656690  [ 3232/10000]\n",
      "loss: 12.992693  [ 6432/10000]\n",
      "loss: 12.513536  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 14.931358 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 12.012935  [   32/10000]\n",
      "loss: 14.154507  [ 3232/10000]\n",
      "loss: 13.271955  [ 6432/10000]\n",
      "loss: 14.383359  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 15.249011 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 12.381216  [   32/10000]\n",
      "loss: 13.421634  [ 3232/10000]\n",
      "loss: 14.288331  [ 6432/10000]\n",
      "loss: 13.868064  [ 9632/10000]\n",
      "Test Error: \n",
      "  Avg loss: 13.933826 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1753.469482  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1375.046623 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1393.149902  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1081.177006 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1070.634888  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 855.929365 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 843.080566  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 675.149559 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 665.871582  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 529.475014 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 513.951538  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 413.286297 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 384.192108  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 321.382824 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 303.892029  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 249.641055 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 215.209137  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 194.485670 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 185.988266  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 152.346682 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 161.047729  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 120.467379 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 103.333595  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 96.294494 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 87.502380  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 78.221948 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 51.189278  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 64.777132 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 56.482235  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 54.635174 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 40.642349  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 47.008555 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 34.031246  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 41.112304 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 32.444004  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 36.653459 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 28.305038  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 33.103569 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 22.108360  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 30.313910 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 22.915443  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 27.989308 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 20.298288  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 26.028316 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 18.428478  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24.367479 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 17.727148  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22.919931 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 17.650623  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21.631615 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 16.217422  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 20.454457 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 14.790951  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19.391603 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 12.491692  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18.413784 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 13.857929  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17.500332 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 13.259695  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 16.660693 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1671.374634  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1590.436813 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1691.145630  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1301.753803 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1319.069946  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 929.559565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 994.788452  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 603.174339 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 630.367798  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 413.620747 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 431.496185  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 336.023662 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 306.103638  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 309.380921 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 318.607788  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 300.200771 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 287.278320  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 295.518588 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 271.056030  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 291.778562 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 302.542206  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 287.749534 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 301.282227  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 283.395562 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 301.178741  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 278.691373 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 260.994995  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 273.693037 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 269.856750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 268.383221 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 257.085022  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 262.403157 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 282.225922  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 256.318242 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 260.777527  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 249.694134 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 269.356628  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 242.792636 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 276.167847  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 235.560853 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 236.512466  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 228.023944 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 219.406097  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 220.274492 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 227.419525  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 212.359745 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 205.698425  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 204.460592 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 183.984100  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 196.280221 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 189.983948  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 188.200589 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 173.735489  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 180.054999 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 178.177917  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 171.958806 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 161.576523  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 163.955297 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 170.899353  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 156.125943 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1830.674805  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1017.747837 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1037.234985  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 242.368839 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 231.201218  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 154.914083 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 158.743790  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 147.652990 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 150.065308  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 140.898570 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 131.694504  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 134.477849 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 132.436020  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 128.058648 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 111.432121  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 121.970660 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 118.417458  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 115.211411 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 111.915359  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 108.630518 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 109.309593  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 102.083641 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 103.664818  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 95.965424 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 88.168121  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 90.092465 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 82.797607  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 84.227170 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 72.185539  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 78.780543 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 64.468994  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 73.996738 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 68.229210  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 69.376676 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 63.208916  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 65.075859 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 54.757545  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 61.312400 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 56.715500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 57.559732 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 47.933651  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 54.137980 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 47.865707  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 50.983448 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 42.089588  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 47.966172 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 38.393707  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 45.188497 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 36.929291  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 42.677136 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 34.536564  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 40.122546 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 34.425560  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 37.856857 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 28.750921  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 35.722251 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 30.145836  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 33.776492 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 26.579973  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 32.086947 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1881.373169  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1365.590889 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1432.585327  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1072.089182 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1032.933228  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 848.493059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 871.275085  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 668.436258 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 657.232239  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 523.730914 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 496.267761  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 408.445413 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 355.646851  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 317.201639 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 272.908173  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 246.559226 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 222.607971  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 191.981532 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 176.035629  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 150.244857 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 112.590950  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 118.868706 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 107.395256  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 95.110031 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 75.265930  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 77.296646 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 59.098732  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 63.850296 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 50.560665  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 53.834051 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 41.342796  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 46.254843 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 39.661179  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 40.585381 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 33.678600  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 36.098390 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 24.470484  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 32.664337 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 25.604246  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29.876281 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 22.216507  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 27.565985 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 22.068710  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25.652496 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 19.642397  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24.028538 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 18.459084  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22.617665 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 17.702055  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21.329285 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 16.922361  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 20.189068 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 15.910388  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19.132878 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 14.409101  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18.178622 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 13.908692  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17.284471 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 11.374245  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 16.429109 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34987.531250  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 32405.297668 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32909.691406  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 30768.985107 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 30760.410156  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29284.208008 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 28669.613281  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 27897.193115 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 26129.501953  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 26582.261780 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 26268.199219  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25329.498230 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 24998.234375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24123.336853 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 24225.390625  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22967.203918 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 23636.677734  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21852.931213 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 22180.345703  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 20780.742920 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 19969.863281  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19755.759644 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 19085.148438  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18770.636658 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 17729.779297  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17819.704712 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 17203.839844  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 16909.557953 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 16964.410156  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 16038.705566 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 15606.030273  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 15201.169006 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 14820.155273  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 14400.967468 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 13489.009766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 13637.101013 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 13007.108398  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 12901.400543 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 12231.736328  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 12200.607544 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 11328.155273  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 11528.534546 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 10745.272461  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10887.739105 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 10009.622070  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10273.245148 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 10097.516602  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9690.575165 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 9062.458008  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9133.840088 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 8640.576172  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8603.687531 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 7953.533691  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8098.287781 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 7276.339355  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7619.511475 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 6872.203613  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7161.587082 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 6874.924805  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 6728.894745 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 33260.488281  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29738.654175 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 28343.224609  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24460.642273 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 26244.044922  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17347.514282 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 18230.560547  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10241.409790 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 9711.916016  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5177.903091 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4958.724609  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2732.338280 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2698.860596  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1971.023262 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2060.167236  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1810.971825 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1931.216309  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1777.754471 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1778.381104  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1759.959373 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1607.047852  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1743.438744 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1608.352173  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1726.264687 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1696.567871  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1709.129864 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1652.790039  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1690.517544 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1654.408325  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1672.237976 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1624.571899  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1653.569443 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1558.746582  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1634.125378 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1739.362549  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1615.001995 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1551.741089  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1594.413074 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1519.487793  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1574.704334 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1516.266724  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1554.210014 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1400.045898  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1534.096256 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1379.420288  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1512.505180 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1406.931274  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1490.956432 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1430.874390  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1469.780949 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1457.101196  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1448.327393 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1437.796753  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1425.743713 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1344.164429  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1403.636433 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1391.841553  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1381.879704 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1274.572632  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1358.951607 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 35939.046875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22655.798523 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 23055.068359  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2740.106430 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2271.486816  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 968.941006 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1021.840393  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 947.208321 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 907.825928  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 900.161043 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 877.071472  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 864.375391 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 825.496399  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 837.522589 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 821.155701  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 812.422659 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 746.677429  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 779.573591 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 726.136902  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 749.313337 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 701.274170  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 711.835001 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 625.380493  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 676.013079 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 628.299866  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 636.038458 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 577.050476  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 600.677614 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 528.152893  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 560.351271 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 501.860931  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 523.376996 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 494.879028  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 491.077428 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 409.260223  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 452.829668 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 385.267883  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 421.598458 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 355.611481  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 390.751132 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 329.401093  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 362.894100 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 306.890717  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 337.790499 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 258.861847  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 311.654456 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 238.358551  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 289.346433 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 202.880493  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 271.239033 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 226.958923  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 250.352123 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 189.788773  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 234.723626 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 166.109329  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 219.373125 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 162.610367  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 203.955601 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 149.152084  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 192.001251 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34554.136719  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 32322.382019 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32676.277344  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 30687.074951 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 30559.800781  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29202.643311 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 27928.226562  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 27820.237122 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 27457.089844  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 26510.442383 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 24403.175781  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25256.502441 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 24818.214844  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24053.785339 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 23673.384766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22899.186340 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 22704.205078  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21788.531433 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 21219.115234  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 20719.828369 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 19768.837891  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19695.392517 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 18896.943359  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18709.120056 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 17698.582031  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17764.766296 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 17862.730469  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 16856.510712 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 15957.357422  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 15984.957520 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 15850.246094  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 15148.416748 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 15466.530273  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 14349.616730 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 14243.674805  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 13584.521149 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 12523.794922  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 12850.783691 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 11968.994141  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 12148.460724 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 12111.581055  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 11476.324524 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 11148.424805  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10837.869507 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 10381.310547  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10227.163940 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 9790.708984  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9644.288025 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 8861.482422  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9087.141113 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 8401.331055  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8560.100006 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 7742.190430  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8055.242432 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 7506.935059  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7575.542221 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 7249.903809  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7121.086624 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 6237.971680  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 6689.426071 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31204.085938  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25188.413757 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 24714.787109  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21531.515381 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 20733.679688  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18544.043152 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 17921.785156  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 15960.029968 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 15032.357422  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 13697.051483 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 12986.959961  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 11728.246429 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 11088.634766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10020.986481 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 8903.918945  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8548.171509 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 7519.546875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7291.397736 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 5962.498047  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 6219.369324 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 5044.776367  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5315.037811 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4155.665527  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4550.625198 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3585.253174  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3915.163719 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3016.680908  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3383.634209 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2393.825195  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2944.698250 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2060.718018  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2580.881325 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1564.165527  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2279.903725 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1421.278931  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2033.864265 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1120.168823  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1833.067200 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1002.611084  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1665.759808 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 849.790161  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1530.662254 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 756.444763  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1417.921299 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 656.046082  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1324.781086 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 559.168701  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1246.407681 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 523.013367  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1180.919460 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 463.452728  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1125.673454 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 437.444763  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1078.424948 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 414.674500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1036.882298 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 357.070129  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1000.755362 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 341.998138  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 968.722395 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31002.154297  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29246.959290 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 29384.755859  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25921.079651 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 25876.873047  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 20731.351562 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 20997.660156  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 14976.244629 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 14506.374023  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 10246.184021 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 10276.008789  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7345.772858 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 7348.407715  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5956.435837 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 5709.494141  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5414.932281 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 5300.348633  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5227.786407 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 5215.509766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5164.465607 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4948.229004  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5140.671051 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4945.933594  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5126.309296 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 5157.011719  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5115.332001 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 4888.552246  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5104.707825 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4955.095215  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5093.657166 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 4922.746094  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5081.451965 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 4726.064941  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5069.257278 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 4911.484863  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5055.267899 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 4919.875000  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5040.384293 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 4960.895508  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5024.913696 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 4778.823242  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5007.166687 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4855.427734  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4989.008179 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4933.133789  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4968.675995 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4745.663086  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4946.634384 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4695.790527  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4922.906418 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4634.868652  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4897.019714 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4597.482910  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4868.389099 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4525.932129  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4837.073288 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4606.681641  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4803.059357 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4704.026855  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4767.132553 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 29817.509766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21252.714233 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 20988.392578  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 6222.110931 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5772.306641  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2845.805008 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2751.806885  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2782.605049 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2590.061035  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2735.844620 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2712.917236  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2722.617004 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2635.768555  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2700.284889 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2550.787354  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2689.239998 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2541.476807  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2670.939415 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2552.051758  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2653.813461 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2584.875732  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2635.028053 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2540.597900  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2620.453033 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2443.725342  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2601.949226 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2376.311768  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2594.623123 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2457.154785  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2573.681305 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2449.417236  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2564.161591 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2345.626465  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2544.672928 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2386.879639  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2525.714073 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2349.824463  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2516.036774 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2326.633789  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2499.482826 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2294.972900  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2485.962608 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2233.308594  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2461.613121 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2169.180664  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2447.214287 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2142.883057  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2429.182823 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2302.246338  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2410.500519 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2217.240723  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2398.844452 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2096.664307  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2379.855118 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2089.842285  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2361.689087 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2064.225342  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2340.075279 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2169.260742  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2330.111137 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30902.921875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 25129.592041 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 24362.150391  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21474.599121 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 20590.812500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 18493.212219 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 17775.794922  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 15910.590363 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 15274.308594  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 13652.228851 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 12953.112305  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 11684.513306 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 10658.968750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9979.857330 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 9014.758789  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8510.958084 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 7300.977539  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7254.523834 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 6134.156738  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 6188.310883 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 5356.984863  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5284.962921 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4403.290039  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4527.032257 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3357.146973  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3891.658592 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2798.683838  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3363.413353 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2363.892578  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2925.397102 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1906.871582  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2563.373619 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1539.897949  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2265.720474 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1350.587646  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 2022.454437 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1120.816284  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1821.835030 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1005.626343  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1657.127632 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 781.641785  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1520.873451 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 710.751587  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1408.996849 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 610.246094  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1316.703609 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 515.223572  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1239.576969 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 456.865692  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1174.616508 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 453.469147  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1119.693214 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 410.225067  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1071.913391 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 368.766052  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 1031.352692 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 352.230316  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 995.548304 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 334.897278  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 963.736538 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 163726.906250  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 154067.027832 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 150809.093750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 144714.732910 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 142899.484375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 136207.994141 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 133753.890625  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 128176.113770 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 125722.906250  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 120530.263916 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 120572.359375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 113236.746338 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 110835.976562  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 106324.082275 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 101310.250000  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 99733.719482 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 93678.062500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 93469.974365 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 88667.382812  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 87526.971924 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 84463.218750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 81892.398193 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 79243.710938  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 76544.732178 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 72594.296875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 71490.853027 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 67897.812500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 66688.634766 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 64035.613281  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 62166.950806 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 57817.585938  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 57887.667847 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 52806.148438  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 53858.161621 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 50607.871094  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 50051.901611 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 46116.335938  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 46480.659180 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 43404.460938  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 43115.739258 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 38768.718750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 39965.498657 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 36315.886719  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 37003.661377 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 34205.339844  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 34234.018188 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 31935.472656  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 31634.818848 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 29661.259766  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29206.813660 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 24969.470703  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 26949.333435 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 23495.921875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24835.927368 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 21674.328125  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22875.842102 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 18641.142578  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21050.137024 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 17851.726562  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19360.816406 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 165366.796875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 150314.008789 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 151301.859375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 120696.163574 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 120403.750000  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 78752.939697 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 79523.703125  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 40019.791626 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 40303.199219  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 17533.882751 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 17126.117188  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 9923.159882 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 10158.481445  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8463.336975 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 8319.411133  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8283.318314 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 8142.679199  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8249.471451 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 8135.583984  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8224.432053 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 8078.555176  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8198.928467 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 7973.805664  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8169.601654 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 8250.228516  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8142.429565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 7915.350586  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8113.317688 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 7942.950195  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8082.830643 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 8053.941406  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8049.613220 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 7833.163574  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 8017.267349 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 7752.685059  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7983.596039 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 7749.386230  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7949.064301 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 7581.835449  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7911.913712 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 7513.698730  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7875.152893 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 7585.687012  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7836.284058 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 7335.331055  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7795.330215 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 7328.840820  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7756.164963 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 7242.857422  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7713.272751 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 7318.754883  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7669.106125 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 7407.942383  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7624.523865 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 7172.931641  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7577.390015 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 7052.038574  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7528.556671 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 6939.122559  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 7477.650162 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 167558.140625  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 96507.270020 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 94524.820312  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 5489.552994 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5409.127441  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4702.085190 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4374.557617  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4572.016495 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4456.171387  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4533.247894 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4310.948242  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4490.486755 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4189.560547  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4403.656509 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4063.453125  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4379.834671 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4267.208008  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4339.511902 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4191.970215  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4315.047180 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4181.444824  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4249.505142 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4034.856201  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4222.334915 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3964.136475  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4187.346046 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3905.003662  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4151.610741 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 3847.338135  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4106.920380 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3816.721680  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4070.297607 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3895.802490  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 4022.866432 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3752.826904  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3962.515366 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3648.119385  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3927.152077 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3363.551758  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3890.297562 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3441.507568  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3825.560249 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3406.281982  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3781.749062 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 3218.094971  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3722.642838 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3152.065430  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3665.826118 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3093.769775  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3610.900803 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2994.604980  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3551.863495 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2821.165039  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3478.453415 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2861.017578  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3435.464546 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2775.901367  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3378.696770 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2653.214355  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 3306.141113 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 165775.796875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 153972.744141 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 154057.500000  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 144632.689941 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 148657.062500  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 136127.158691 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 135132.984375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 128106.232666 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 128474.523438  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 120473.092041 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 118107.609375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 113202.694336 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 113793.171875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 106268.612549 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 105217.539062  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 99692.232422 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 96449.992188  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 93431.069580 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 89636.671875  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 87480.451904 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 84706.492188  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 81833.739258 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 78497.242188  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 76493.365967 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 73518.781250  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 71428.441406 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 70319.828125  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 66638.618652 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 63522.859375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 62116.474365 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 59795.105469  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 57849.585815 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 52806.074219  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 53818.567505 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 50620.394531  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 50018.313721 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 45849.828125  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 46448.604248 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 44385.058594  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 43093.230469 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 38070.484375  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 39937.163330 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 36794.468750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 36978.003174 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 32207.214844  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 34206.906494 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 30356.185547  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 31610.314697 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 28338.130859  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 29186.805359 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 24683.650391  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 26931.283386 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 22849.814453  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 24825.464966 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 20671.468750  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 22863.834167 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 20249.380859  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 21036.811890 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 18720.082031  [   32/ 1000]\n",
      "Test Error: \n",
      "  Avg loss: 19348.274475 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1843.860962  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1765.257488 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1751.508789  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1698.118046 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1693.457153  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1635.740986 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1586.371094  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1577.756012 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1498.729370  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1524.239025 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1426.444214  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1474.570217 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1378.501831  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1428.281967 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1304.971680  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1384.720863 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1367.962158  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1343.646095 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1266.367310  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1304.844769 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1203.736816  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1267.931484 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1180.643066  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1232.456917 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1104.013306  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1198.523762 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1127.899414  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1165.699043 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1070.026978  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1134.003128 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1029.281982  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1103.400280 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 936.851807  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1073.823368 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 953.079163  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1045.133543 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 890.954773  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1017.521971 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 902.907898  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 990.787380 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 915.084351  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 964.679550 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 843.623047  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 939.371565 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 784.288574  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 914.859514 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 827.342102  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 891.029894 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 758.002502  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 867.864676 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 706.213074  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 845.439053 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 721.897827  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 823.711985 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 698.050293  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 802.460693 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 643.114868  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 781.671953 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 637.908936  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 761.389006 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1828.350342  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1727.239468 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1731.409058  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1711.870449 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1695.876465  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1695.025848 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1709.466064  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1676.594444 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1678.339844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1656.465424 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1637.403931  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1634.572941 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1641.081299  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1610.779026 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1587.366821  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1585.101532 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1571.448730  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1557.398712 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1474.196533  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1527.794624 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1528.288696  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1496.104816 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1466.670654  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1462.624645 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1518.342041  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1427.374508 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1435.685913  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1390.436905 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1370.907227  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1351.792301 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1320.177856  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1311.718636 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1264.336060  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1270.406815 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1281.014038  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1227.709381 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1245.998657  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1184.031399 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1152.643921  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1139.795818 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1101.532959  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1095.216125 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1097.564819  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1050.409193 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1016.677551  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1005.827393 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 976.800781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 961.381424 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 953.554626  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 917.403633 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 895.633972  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 873.761749 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 884.363831  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 830.956638 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 847.289062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 789.718725 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 776.936157  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 750.311550 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 736.774780  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 712.497475 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1864.725342  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1730.581963 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1782.529175  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1655.068176 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1580.152710  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1563.828243 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1506.255371  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1455.260864 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1447.633179  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1332.260334 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1242.888794  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1199.487728 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1119.649414  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1062.457071 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1035.581543  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 926.856649 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 828.578674  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 797.594915 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 731.787415  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 675.602695 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 631.252563  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 561.830372 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 495.710968  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 459.433251 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 376.796326  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 372.204642 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 293.726410  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 304.059729 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 234.159180  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 255.800472 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 205.381088  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 224.185042 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 189.532867  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 204.786491 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 184.427536  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 194.250664 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 148.758087  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 188.476260 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 150.930710  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 184.603643 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 161.946304  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 182.533161 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 137.242691  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 181.316960 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 136.122025  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 181.315581 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 135.844147  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 182.670950 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 147.952133  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 183.729485 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 141.520248  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 184.990381 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 141.236099  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 184.684864 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 134.798386  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 183.170042 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 141.691772  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 180.823127 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 141.737976  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 179.077134 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1832.239746  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1752.808514 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1700.764038  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1686.115089 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1676.536255  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1623.840801 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1567.336304  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1566.388359 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1489.125366  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1513.271885 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1486.713379  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1463.927528 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1375.417603  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1417.753441 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1348.999512  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1374.360260 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1305.172363  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1333.119877 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1219.630615  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1294.245735 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1252.455200  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1257.350784 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1194.178833  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1222.202255 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1148.502563  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1188.133808 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1109.595947  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1155.300304 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1026.642456  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1123.718246 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1014.209473  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1093.330936 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 978.142639  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1063.994007 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 951.267090  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1035.536568 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 883.459534  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1007.817488 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 903.138184  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 980.968927 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 865.124695  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 955.014908 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 814.609070  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 929.795259 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 786.044861  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 905.208763 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 753.031555  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 881.371300 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 728.895142  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 858.247087 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 683.435059  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 835.758713 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 710.069946  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 813.918720 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 656.271729  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 792.614079 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 656.140686  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 771.759993 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 617.696106  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 751.457035 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34633.933594  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33841.557373 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32592.818359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33601.798462 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 32724.494141  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33366.250610 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 33761.054688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33135.584534 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 32269.414062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32909.168091 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 32337.580078  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32686.476624 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 30982.357422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32467.980957 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 30393.125000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32253.212891 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 30889.609375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32042.298218 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 30224.082031  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31833.769348 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 29772.132812  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31628.500366 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 30785.783203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31427.148560 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 29777.500000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31229.627014 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 29823.734375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31034.556213 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 28709.417969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30842.000732 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 29507.335938  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30652.519470 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 29956.425781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30465.088318 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 29491.542969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30279.199829 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 28410.019531  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30096.067810 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 27689.068359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29915.208923 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 28034.767578  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29734.580139 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 27884.152344  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29555.112915 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 28660.025391  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29376.574829 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 27888.830078  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29200.655457 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 27267.044922  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29026.131287 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 26882.087891  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28853.428711 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 26255.304688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28681.877502 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 26546.974609  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28510.361816 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 26401.929688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28340.407166 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 26160.714844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28172.040100 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30859.230469  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32453.159119 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32247.136719  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32176.225647 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 31465.984375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31875.280518 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 31620.804688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31546.723022 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 31194.425781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31188.914917 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 29228.105469  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30800.575256 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 30278.302734  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30379.120422 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 29825.109375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29923.362366 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 27935.482422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29430.283630 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 26922.929688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28898.809265 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 27170.177734  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28330.920654 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 27544.914062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27726.542847 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 27605.984375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27087.785889 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 25571.865234  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26416.194824 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 25312.554688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25706.017822 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 24308.119141  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24960.261292 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 24560.443359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24186.830322 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 23106.484375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23388.958313 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 22445.310547  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22563.405579 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 21183.607422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21714.690430 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 20459.074219  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20846.743408 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 20108.396484  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19963.210083 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 19209.017578  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19070.810791 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 17926.904297  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18170.661011 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 17885.529297  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17267.837128 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 17006.498047  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 16369.925598 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 16273.910156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 15477.023010 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 14869.964844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 14593.115204 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 14523.741211  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 13720.995026 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 13468.613281  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 12862.873505 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 33306.988281  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33603.615112 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32403.064453  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32842.481689 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 31607.292969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31843.644226 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 31286.474609  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30559.502563 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 29005.792969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28994.124207 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 28141.462891  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27163.148254 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 24637.875000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25088.656616 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 24117.115234  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22765.215210 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 21025.357422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20198.900269 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 17948.570312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17411.670227 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 14751.039062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 14516.989014 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 11803.963867  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 11682.218048 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 8661.410156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9039.892410 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 6534.983887  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 6682.010925 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4231.875488  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 4750.190720 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3054.946289  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3319.675629 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1897.896729  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 2379.996124 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1344.089355  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1855.295578 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1152.075073  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1583.479980 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1136.661865  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1443.457153 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1172.232788  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1399.037575 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1040.762451  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1390.537415 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1115.988403  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1418.156769 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1001.179626  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1470.537582 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 939.305054  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1527.528824 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 956.161743  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1599.834061 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 899.720764  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1643.660057 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 882.578613  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1649.649422 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 869.153809  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1632.055824 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 966.705994  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 1591.397827 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 32948.066406  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33964.010132 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 32815.183594  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33724.194214 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 32146.492188  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33489.158936 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 32103.134766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33258.055542 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 30773.304688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 33031.986633 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 31752.810547  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32810.058899 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 33400.816406  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32591.991638 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 31172.000000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32377.439026 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 31751.732422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 32165.768921 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 30994.402344  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31956.752502 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 30533.734375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31751.909851 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 29334.414062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31550.683899 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 30855.685547  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31352.177551 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 29413.523438  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 31156.553772 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 28868.917969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30963.579468 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 29741.177734  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30773.074768 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 29210.589844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30584.648682 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 29071.722656  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30398.727905 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 28613.339844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30214.067139 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 29660.892578  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30031.035339 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 28729.767578  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29850.006714 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 28066.947266  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29670.733276 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 27692.693359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29492.972778 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 28798.658203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29315.211304 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 27534.990234  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29140.290955 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 27273.259766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28967.662354 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 27291.312500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28795.667786 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 26606.789062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28624.568726 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 26690.695312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28455.053833 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 27429.914062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28287.898804 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31294.070312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29961.179749 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 29046.550781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29122.843628 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 27489.367188  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28353.477051 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 27282.384766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27646.234558 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 26056.275391  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26993.829956 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 25433.812500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26386.855225 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 24623.470703  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25819.782837 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 24251.476562  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25288.801208 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 23409.535156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24786.846497 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 22822.550781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24307.776428 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 22282.658203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23847.205750 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 21293.761719  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23401.915283 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 20949.664062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22971.612793 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 20666.613281  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22556.123474 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 19797.626953  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22152.497864 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 19206.261719  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21758.905518 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 18883.341797  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21373.529846 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 18759.138672  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20998.294861 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 18142.044922  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20632.770081 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 17248.919922  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20274.354309 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 17052.140625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19921.982422 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 16778.212891  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19577.786987 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 16453.935547  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19240.248047 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 15736.682617  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18909.460999 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 15771.200195  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18583.961731 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 15331.963867  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18264.085510 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 14666.032227  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17951.109253 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 13802.849609  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17644.945801 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 13824.235352  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17342.979187 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 13546.332031  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17045.707458 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30185.400391  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30518.351135 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 30192.550781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30413.393494 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 30261.292969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30289.284302 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 28723.699219  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30143.923767 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 30198.515625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29975.029724 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 30075.443359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29780.902832 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 29590.810547  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29559.528015 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 29400.140625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29309.051270 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 28646.363281  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29028.446899 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 28803.160156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28716.279846 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 28845.814453  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28372.792236 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 28273.947266  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27997.468750 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 27842.705078  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27588.904480 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 27244.697266  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27147.531433 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 26134.277344  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26674.266418 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 25610.509766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26168.464478 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 26581.029297  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25631.975525 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 24826.960938  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25068.556763 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 25068.328125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24478.417908 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 24291.667969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23862.763367 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 23014.205078  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23226.895020 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 22864.974609  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22573.515381 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 22070.488281  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21906.624756 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 21809.822266  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21226.230774 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 20994.042969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20537.010620 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 20535.019531  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19841.256592 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 19197.076172  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19139.572388 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 18617.443359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18436.959778 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 18430.701172  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17738.419983 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 17220.794922  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17048.289001 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30495.857422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 30388.666748 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 29717.705078  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29726.070740 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 29488.390625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28769.012390 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 27627.289062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27526.313660 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 26358.927734  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26045.565979 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 25186.279297  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24405.615356 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 23042.335938  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22675.619507 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 21253.375000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20884.046936 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 20003.962891  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19039.978271 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 17164.783203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17144.775818 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 15071.094727  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 15204.359741 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 13276.675781  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 13252.794434 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 10846.532227  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 11331.679779 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 9078.179688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9508.873108 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 7088.211426  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 7879.914093 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 5685.600098  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 6488.661972 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 4260.500000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 5386.675354 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3463.440430  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 4583.530777 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3186.109619  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 4030.637817 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2880.290527  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3686.136551 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2755.512451  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3503.539330 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2646.929688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3402.292053 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2662.698730  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3351.188019 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2723.126221  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3363.814796 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2627.250000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3397.248581 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2566.670654  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3451.743156 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2578.740723  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3502.486313 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2465.181152  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3538.833107 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2385.440430  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3552.895309 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2508.881836  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 3555.094986 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 30573.607422  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29921.125916 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 29396.533203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 29085.867798 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 28525.900391  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 28319.457520 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 27609.494141  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 27613.890930 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 25834.974609  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26960.407166 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 25199.572266  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 26353.945007 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 24768.054688  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25784.382141 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 23971.216797  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 25247.859314 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 22815.837891  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24739.367432 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 22996.347656  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24254.942810 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 21889.634766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23792.046692 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 21582.214844  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 23347.644897 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 20781.017578  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22917.496460 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 20422.187500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22498.866577 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 19360.851562  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 22093.043091 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 19492.355469  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21700.009827 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 18914.292969  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 21317.178650 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 18542.074219  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20942.110352 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 18059.654297  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20574.876953 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 17464.025391  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 20215.498901 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 16801.765625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19863.537476 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 16324.318359  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19518.153687 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 15860.884766  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 19178.942017 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 15750.912109  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18845.399292 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 14871.628906  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18517.562561 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 14845.039062  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 18196.307617 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 14905.552734  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17882.436462 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 13973.791016  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17576.143738 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 13889.236328  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 17275.526306 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 13564.026367  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 16981.311523 \n",
      "\n",
      "MLR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 165225.484375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 164000.139648 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 158454.625000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 162434.239258 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 157932.500000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 160936.030762 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 157364.078125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 159500.522949 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 154288.343750  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 158119.930176 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 153619.375000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 156788.615234 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 150871.656250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 155493.971680 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 149162.687500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 154234.561035 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 146165.312500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 153006.673340 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 149517.765625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 151805.566406 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 148347.015625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 150633.678223 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 141767.234375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 149485.290527 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 139037.984375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 148355.552734 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 139775.625000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 147239.340820 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 140228.406250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 146135.326660 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 138831.125000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 145044.617188 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 136404.796875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 143969.667969 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 133662.640625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 142907.894531 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 134348.156250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 141853.514160 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 135440.234375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 140805.664551 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 131174.375000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 139770.910156 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 128533.031250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 138744.115234 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 130637.437500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 137728.815918 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 129471.820312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 136722.316406 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 126528.218750  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 135722.550781 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 124086.109375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 134726.149170 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 120950.359375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 133737.619873 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 121380.460938  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 132758.108154 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 124282.820312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 131782.896973 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 119522.078125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 130816.545898 \n",
      "\n",
      "PTR ---------------------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 162249.156250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 162302.976562 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 156967.156250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 161287.695801 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 159587.953125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 160097.407227 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 156234.703125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 158715.975098 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 158821.812500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 157125.418945 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 154480.484375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 155310.111816 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 151375.546875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 153255.326172 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 151164.125000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 150948.040527 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 147709.046875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 148381.283203 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 142675.562500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 145552.528809 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 141486.953125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 142447.391113 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 138838.468750  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 139072.429688 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 137070.546875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 135424.083984 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 132119.125000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 131527.146484 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 127799.000000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 127383.763916 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 125222.296875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 123000.787842 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 119350.750000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 118405.853516 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 117381.976562  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 113627.269531 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 111044.898438  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 108693.285889 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 106377.890625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 103632.851807 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 100087.156250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 98479.529053 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 94641.359375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 93241.662109 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 90155.257812  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 87945.311768 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 85837.609375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 82644.796143 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 81158.226562  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 77381.040771 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 75712.195312  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 72175.487305 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 69784.000000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 67060.567749 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 63417.109375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 62071.208130 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 59430.871094  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 57219.890259 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 56559.148438  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 52556.753784 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 162339.281250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 163100.820312 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 159661.015625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 158954.934570 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 153415.953125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 152799.010254 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 147997.265625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 144903.717773 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 138016.890625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 135500.699707 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 128081.656250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 124399.241943 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 114916.390625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 111416.240967 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 100520.648438  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 96793.907715 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 82778.507812  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 81126.242432 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 67190.242188  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 65173.352539 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 49078.644531  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 49775.948975 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 34093.773438  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 35922.410156 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 21957.419922  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 24612.004578 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 11968.815430  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 16426.731171 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 7049.791016  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 11110.337769 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 4992.931152  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 8329.057205 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 5394.657715  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 7054.508102 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 5798.535156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 6632.855804 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 6400.118652  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 6829.581619 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 6169.306641  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 7481.621216 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 4931.303711  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 8251.155258 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4450.247070  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9099.082565 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4309.110352  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9789.078674 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4659.160156  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 10136.037140 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4102.834473  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 10222.749939 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4191.888184  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 10198.245453 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4247.709473  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9992.648407 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4311.783203  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9574.754150 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4224.113770  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9255.348190 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4225.436035  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 9034.955505 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 164369.328125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 163857.224609 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 158631.937500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 162291.754395 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 157837.015625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 160789.961914 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 155679.218750  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 159350.641602 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 155470.015625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 157968.436035 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 151650.765625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 156634.341797 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 147833.390625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 155337.982910 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 151592.671875  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 154077.287109 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 147046.078125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 152854.993652 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 147807.656250  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 151660.328613 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 148006.187500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 150491.739258 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 142879.312500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 149345.737793 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 144183.375000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 148218.592773 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 140424.437500  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 147106.667969 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 141095.984375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 146008.746094 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 136922.515625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 144924.998047 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 139144.875000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 143851.146484 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 135297.703125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 142791.107422 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 131601.328125  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 141741.166504 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 134269.609375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 140700.867188 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 130841.250000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 139670.330078 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 128740.851562  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 138645.493164 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 127784.000000  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 137624.552734 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 126586.617188  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 136613.966309 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 126187.140625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 135614.330566 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 124263.593750  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 134622.999512 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 123511.632812  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 133636.210938 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 123628.890625  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 132658.839600 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 121441.757812  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 131688.887695 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 120559.359375  [   32/  100]\n",
      "Test Error: \n",
      "  Avg loss: 130721.031494 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete old models for retrained\n",
    "\n",
    "!rm trained_models/*\n",
    "!rm training_history/*\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "ns = [10000, 1000, 100]\n",
    "contexts = ['10000_20_10_5_0', '10000_20_10_20_0', '10000_40_20_5_0', '10000_40_20_20_0']\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "lr = 0.001\n",
    "skip_training = False\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Custom Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        return x, y\n",
    "    \n",
    "# Training and testing loop:\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return train_loss / num_batches\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss=  0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n  Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "# Utils function for saving:\n",
    "\n",
    "def create_history_df():\n",
    "    history = pd.DataFrame(columns= ['Epochs', 'TrainLoss', 'TestLoss'])\n",
    "    return history\n",
    "\n",
    "def add_record_to_dataframe(df, record):\n",
    "    # Convert the record tuple to a DataFrame with a single row\n",
    "    new_row = pd.DataFrame([record], columns=df.columns)\n",
    "    \n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_dataframe_to_pickle(df, n, context, name):\n",
    "    filepath = f'training_history/{name}_{context}_{n}.pickle'\n",
    "    df.to_pickle(filepath)\n",
    "    return filepath\n",
    "    \n",
    "\n",
    "def save_model(model, n, context, name):\n",
    "    filepath = f'trained_models/{name}_{context}_{n}.pt'\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return filepath\n",
    "\n",
    "# def save_history_df(history, n, context, name):\n",
    "\n",
    "# Training results\n",
    "\n",
    "task = []\n",
    "nof_data = []\n",
    "dir_of_trained_modes = []\n",
    "dir_of_training_history = []\n",
    "\n",
    "# Loop\n",
    "\n",
    "if not skip_training:\n",
    "    for n in ns:\n",
    "        for context in contexts:\n",
    "            rank = int(context.split('_')[3])\n",
    "            X = np.load('data/spd2spd/X_'+context+'.npy')\n",
    "            Y = np.load('data/spd2spd/Y_'+context+'.npy')\n",
    "            Xt = np.load('data/spd2spd/Xt_'+context+'.npy')\n",
    "            Yt = np.load('data/spd2spd/Yt_'+context+'.npy')\n",
    "    \n",
    "            # Create training dataset and dataloader\n",
    "            train_dataset = CustomDataset(X[0:n], Y[0:n])\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Create test dataset and dataloader\n",
    "            test_dataset = CustomDataset(Xt, Yt)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "            # Multivariate Linear Regression:\n",
    "            print(\"MLR ---------------------------------------------\")\n",
    "            history = create_history_df()\n",
    "            model = MVl(X[0].shape, Y[0].shape)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "                history = add_record_to_dataframe(history, (t, train_loss, test_loss))\n",
    "    \n",
    "            dir_of_trained_modes.append(save_model(model, n, context, \"MVL\"))\n",
    "            dir_of_training_history.append(save_dataframe_to_pickle(history, n, context, \"MVL\"))\n",
    "            task.append(context)\n",
    "            nof_data.append(n)\n",
    "    \n",
    "            # Partial Trace Regression:\n",
    "            print(\"PTR ---------------------------------------------\")\n",
    "            history = create_history_df()\n",
    "            output_shape = Y.shape[1]\n",
    "            input_shape = X[0].shape\n",
    "            model = KrausLayer(input_shape, output_shape, rank)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "                history = add_record_to_dataframe(history, (t, train_loss, test_loss))\n",
    "    \n",
    "            dir_of_trained_modes.append(save_model(model, n, context, \"PTR\"))\n",
    "            dir_of_training_history.append(save_dataframe_to_pickle(history, n, context, \"PTR\"))\n",
    "            task.append(context)\n",
    "            nof_data.append(n)\n",
    "    \n",
    "    \n",
    "            # Reduced Rank Regression\n",
    "            # \n",
    "            history = create_history_df()    \n",
    "            model = RRMVL(rank * 10, X[0].shape, Y[0].shape)\n",
    "            loss_fn = nn.MSELoss() \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "                history = add_record_to_dataframe(history, (t, train_loss, test_loss))\n",
    "            dir_of_trained_modes.append(save_model(model, n, context, \"RRR\"))\n",
    "            dir_of_training_history.append(save_dataframe_to_pickle(history, n, context, \"RRR\"))\n",
    "            task.append(context)\n",
    "            nof_data.append(n)\n",
    "    \n",
    "            # Trace Regression\n",
    "            history = create_history_df()\n",
    "            model = TraceLayer(X[0].shape, Y[0].shape)\n",
    "            loss_fn = nn.MSELoss() \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "                history = add_record_to_dataframe(history, (t, train_loss, test_loss))\n",
    "            dir_of_trained_modes.append(save_model(model, n, context, \"TR\"))\n",
    "            dir_of_training_history.append(save_dataframe_to_pickle(history, n, context, \"TR\"))\n",
    "            task.append(context)\n",
    "            nof_data.append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>nof_data</th>\n",
       "      <th>dir_of_trained_models</th>\n",
       "      <th>dir_of_training_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>10000</td>\n",
       "      <td>trained_models/MVL_10000_20_10_5_0_10000.pt</td>\n",
       "      <td>training_history/MVL_10000_20_10_5_0_10000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>10000</td>\n",
       "      <td>trained_models/PTR_10000_20_10_5_0_10000.pt</td>\n",
       "      <td>training_history/PTR_10000_20_10_5_0_10000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>10000</td>\n",
       "      <td>trained_models/RRR_10000_20_10_5_0_10000.pt</td>\n",
       "      <td>training_history/RRR_10000_20_10_5_0_10000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>10000</td>\n",
       "      <td>trained_models/TR_10000_20_10_5_0_10000.pt</td>\n",
       "      <td>training_history/TR_10000_20_10_5_0_10000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>trained_models/MVL_10000_20_10_5_0_1000.pt</td>\n",
       "      <td>training_history/MVL_10000_20_10_5_0_1000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>trained_models/PTR_10000_20_10_5_0_1000.pt</td>\n",
       "      <td>training_history/PTR_10000_20_10_5_0_1000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>trained_models/RRR_10000_20_10_5_0_1000.pt</td>\n",
       "      <td>training_history/RRR_10000_20_10_5_0_1000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>trained_models/TR_10000_20_10_5_0_1000.pt</td>\n",
       "      <td>training_history/TR_10000_20_10_5_0_1000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>100</td>\n",
       "      <td>trained_models/MVL_10000_20_10_5_0_100.pt</td>\n",
       "      <td>training_history/MVL_10000_20_10_5_0_100.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>100</td>\n",
       "      <td>trained_models/PTR_10000_20_10_5_0_100.pt</td>\n",
       "      <td>training_history/PTR_10000_20_10_5_0_100.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>100</td>\n",
       "      <td>trained_models/RRR_10000_20_10_5_0_100.pt</td>\n",
       "      <td>training_history/RRR_10000_20_10_5_0_100.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10000_20_10_5_0</td>\n",
       "      <td>100</td>\n",
       "      <td>trained_models/TR_10000_20_10_5_0_100.pt</td>\n",
       "      <td>training_history/TR_10000_20_10_5_0_100.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               task  nof_data                        dir_of_trained_models  \\\n",
       "0   10000_20_10_5_0     10000  trained_models/MVL_10000_20_10_5_0_10000.pt   \n",
       "1   10000_20_10_5_0     10000  trained_models/PTR_10000_20_10_5_0_10000.pt   \n",
       "2   10000_20_10_5_0     10000  trained_models/RRR_10000_20_10_5_0_10000.pt   \n",
       "3   10000_20_10_5_0     10000   trained_models/TR_10000_20_10_5_0_10000.pt   \n",
       "16  10000_20_10_5_0      1000   trained_models/MVL_10000_20_10_5_0_1000.pt   \n",
       "17  10000_20_10_5_0      1000   trained_models/PTR_10000_20_10_5_0_1000.pt   \n",
       "18  10000_20_10_5_0      1000   trained_models/RRR_10000_20_10_5_0_1000.pt   \n",
       "19  10000_20_10_5_0      1000    trained_models/TR_10000_20_10_5_0_1000.pt   \n",
       "32  10000_20_10_5_0       100    trained_models/MVL_10000_20_10_5_0_100.pt   \n",
       "33  10000_20_10_5_0       100    trained_models/PTR_10000_20_10_5_0_100.pt   \n",
       "34  10000_20_10_5_0       100    trained_models/RRR_10000_20_10_5_0_100.pt   \n",
       "35  10000_20_10_5_0       100     trained_models/TR_10000_20_10_5_0_100.pt   \n",
       "\n",
       "                              dir_of_training_history  \n",
       "0   training_history/MVL_10000_20_10_5_0_10000.pickle  \n",
       "1   training_history/PTR_10000_20_10_5_0_10000.pickle  \n",
       "2   training_history/RRR_10000_20_10_5_0_10000.pickle  \n",
       "3    training_history/TR_10000_20_10_5_0_10000.pickle  \n",
       "16   training_history/MVL_10000_20_10_5_0_1000.pickle  \n",
       "17   training_history/PTR_10000_20_10_5_0_1000.pickle  \n",
       "18   training_history/RRR_10000_20_10_5_0_1000.pickle  \n",
       "19    training_history/TR_10000_20_10_5_0_1000.pickle  \n",
       "32    training_history/MVL_10000_20_10_5_0_100.pickle  \n",
       "33    training_history/PTR_10000_20_10_5_0_100.pickle  \n",
       "34    training_history/RRR_10000_20_10_5_0_100.pickle  \n",
       "35     training_history/TR_10000_20_10_5_0_100.pickle  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = pd.read_pickle('records.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>TrainLoss</th>\n",
       "      <th>TestLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>122841.458441</td>\n",
       "      <td>88300.934814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63603.440682</td>\n",
       "      <td>43463.740967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29580.851357</td>\n",
       "      <td>18988.123535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12091.496198</td>\n",
       "      <td>7271.216919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4339.040638</td>\n",
       "      <td>2523.921295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1474.926649</td>\n",
       "      <td>935.139261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>610.431482</td>\n",
       "      <td>488.732369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>384.911843</td>\n",
       "      <td>363.194283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>313.900890</td>\n",
       "      <td>307.719258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>270.747208</td>\n",
       "      <td>265.874728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>232.639387</td>\n",
       "      <td>228.307515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>197.001876</td>\n",
       "      <td>193.445065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>164.222023</td>\n",
       "      <td>161.714232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>134.602259</td>\n",
       "      <td>133.020982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>108.567267</td>\n",
       "      <td>107.971532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>86.233242</td>\n",
       "      <td>86.411719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>67.663874</td>\n",
       "      <td>68.446740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>52.738682</td>\n",
       "      <td>53.859297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>41.168570</td>\n",
       "      <td>42.599728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>32.529317</td>\n",
       "      <td>34.129317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>26.355452</td>\n",
       "      <td>28.033679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>22.095597</td>\n",
       "      <td>23.779379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>19.245746</td>\n",
       "      <td>20.905063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>17.354566</td>\n",
       "      <td>18.951406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>16.071446</td>\n",
       "      <td>17.580921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>15.115629</td>\n",
       "      <td>16.499151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>14.320653</td>\n",
       "      <td>15.611380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>13.610584</td>\n",
       "      <td>14.931358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>13.641322</td>\n",
       "      <td>15.249011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>13.557232</td>\n",
       "      <td>13.933826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs      TrainLoss      TestLoss\n",
       "0       0  122841.458441  88300.934814\n",
       "1       1   63603.440682  43463.740967\n",
       "2       2   29580.851357  18988.123535\n",
       "3       3   12091.496198   7271.216919\n",
       "4       4    4339.040638   2523.921295\n",
       "5       5    1474.926649    935.139261\n",
       "6       6     610.431482    488.732369\n",
       "7       7     384.911843    363.194283\n",
       "8       8     313.900890    307.719258\n",
       "9       9     270.747208    265.874728\n",
       "10     10     232.639387    228.307515\n",
       "11     11     197.001876    193.445065\n",
       "12     12     164.222023    161.714232\n",
       "13     13     134.602259    133.020982\n",
       "14     14     108.567267    107.971532\n",
       "15     15      86.233242     86.411719\n",
       "16     16      67.663874     68.446740\n",
       "17     17      52.738682     53.859297\n",
       "18     18      41.168570     42.599728\n",
       "19     19      32.529317     34.129317\n",
       "20     20      26.355452     28.033679\n",
       "21     21      22.095597     23.779379\n",
       "22     22      19.245746     20.905063\n",
       "23     23      17.354566     18.951406\n",
       "24     24      16.071446     17.580921\n",
       "25     25      15.115629     16.499151\n",
       "26     26      14.320653     15.611380\n",
       "27     27      13.610584     14.931358\n",
       "28     28      13.641322     15.249011\n",
       "29     29      13.557232     13.933826"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.read_pickle('./training_history/TR_10000_40_20_20_0_10000.pickle')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MVL_10000_40_20_20_0_10000.pickle',\n",
       " 'PTR_10000_40_20_5_0_100.pickle',\n",
       " 'TR_10000_20_10_20_0_10000.pickle',\n",
       " 'RRR_10000_20_10_20_0_100.pickle',\n",
       " 'TR_10000_40_20_20_0_1000.pickle',\n",
       " 'RRR_10000_40_20_5_0_10000.pickle',\n",
       " 'TR_10000_40_20_20_0_10000.pickle',\n",
       " 'PTR_10000_40_20_20_0_10000.pickle',\n",
       " 'RRR_10000_40_20_5_0_1000.pickle',\n",
       " 'MVL_10000_40_20_20_0_100.pickle',\n",
       " 'MVL_10000_20_10_5_0_100.pickle',\n",
       " 'MVL_10000_20_10_5_0_1000.pickle',\n",
       " 'MVL_10000_20_10_20_0_100.pickle',\n",
       " 'MVL_10000_20_10_20_0_1000.pickle',\n",
       " 'RRR_10000_20_10_5_0_10000.pickle',\n",
       " 'MVL_10000_40_20_20_0_1000.pickle',\n",
       " 'TR_10000_40_20_5_0_100.pickle',\n",
       " 'MVL_10000_40_20_5_0_10000.pickle',\n",
       " 'PTR_10000_40_20_20_0_100.pickle',\n",
       " 'RRR_10000_20_10_20_0_10000.pickle',\n",
       " 'RRR_10000_20_10_5_0_1000.pickle',\n",
       " 'TR_10000_20_10_5_0_100.pickle',\n",
       " 'TR_10000_20_10_5_0_10000.pickle',\n",
       " 'TR_10000_20_10_5_0_1000.pickle',\n",
       " 'RRR_10000_20_10_20_0_1000.pickle',\n",
       " 'PTR_10000_20_10_20_0_1000.pickle',\n",
       " 'RRR_10000_20_10_5_0_100.pickle',\n",
       " 'RRR_10000_40_20_20_0_10000.pickle',\n",
       " 'RRR_10000_40_20_20_0_100.pickle',\n",
       " 'MVL_10000_40_20_5_0_100.pickle',\n",
       " 'PTR_10000_20_10_20_0_100.pickle',\n",
       " 'TR_10000_20_10_20_0_1000.pickle',\n",
       " 'PTR_10000_20_10_20_0_10000.pickle',\n",
       " 'MVL_10000_40_20_5_0_1000.pickle',\n",
       " 'PTR_10000_40_20_5_0_10000.pickle',\n",
       " 'PTR_10000_40_20_5_0_1000.pickle',\n",
       " 'MVL_10000_20_10_5_0_10000.pickle',\n",
       " 'TR_10000_20_10_20_0_100.pickle',\n",
       " 'RRR_10000_40_20_20_0_1000.pickle',\n",
       " 'RRR_10000_40_20_5_0_100.pickle',\n",
       " 'MVL_10000_20_10_20_0_10000.pickle',\n",
       " 'PTR_10000_40_20_20_0_1000.pickle',\n",
       " 'TR_10000_40_20_5_0_10000.pickle',\n",
       " 'TR_10000_40_20_5_0_1000.pickle',\n",
       " 'TR_10000_40_20_20_0_100.pickle',\n",
       " 'PTR_10000_20_10_5_0_100.pickle',\n",
       " 'PTR_10000_20_10_5_0_10000.pickle',\n",
       " 'PTR_10000_20_10_5_0_1000.pickle']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_files = [f for f in os.listdir(\"training_history\") if f.endswith(\".pickle\")]\n",
    "pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          26909.13098417532,
          16275.101730980432,
          9300.261358389078,
          4945.369637486272,
          2422.485297352361,
          1093.1408972206968,
          468.90976069148735,
          210.14685563157542,
          113.36067877333765,
          76.81764747692755,
          59.04802198074877,
          46.85341428567807,
          37.14809249536679,
          29.323727470617325,
          23.242462615235546,
          18.719741854804774,
          15.516894757938081,
          13.321498173113449,
          11.84067175563532,
          10.829338140761891,
          10.05861563271227,
          9.398590925783395,
          8.764035305656945,
          8.111374621954969,
          7.424535946343273,
          6.690759680141656,
          5.935959502150076,
          5.164407313441316,
          4.394198605808587,
          3.643402951974838
         ]
        },
        {
         "name": "Test Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          20874.14678955078,
          12307.698516845703,
          6788.164611816406,
          3464.542922973633,
          1627.2221412658691,
          711.899980545044,
          308.9566249847412,
          151.33745431900024,
          92.89739847183228,
          68.29857051372528,
          53.81277596950531,
          42.82179617881775,
          33.94438046216965,
          26.908684253692627,
          21.53892594575882,
          17.63583505153656,
          14.909693658351898,
          13.067027419805527,
          11.810438752174377,
          10.906869530677795,
          10.184191077947617,
          9.503104656934738,
          8.824320122599602,
          8.110603302717209,
          7.366630092263222,
          6.59752444922924,
          5.777358859777451,
          4.965609207749367,
          4.175399638712406,
          3.4106690660119057
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training History - TR_10000_20_10_20_0_10000.pickle"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          122934.0396865016,
          63698.146153654154,
          29636.468369359027,
          12120.172729882188,
          4350.645407972244,
          1479.4517956815969,
          612.1998833117012,
          385.6834382371019,
          314.4796549154166,
          271.27999717054274,
          233.07510492976863,
          197.44447126784644,
          164.55802537229496,
          134.95092512624333,
          108.81551129520892,
          86.43376920169915,
          67.83996769719231,
          52.8569558969321,
          41.25538694363433,
          32.602304830337864,
          26.400323794672666,
          22.125371043293622,
          19.26352724556725,
          17.37571843668295,
          16.08084137523517,
          15.127912116126891,
          14.324213585533654,
          13.604417944106812,
          13.48021872279743,
          13.674377401796773
         ]
        },
        {
         "name": "Test Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          88399.4423828125,
          43540.052490234375,
          19022.505737304688,
          7289.415817260742,
          2529.9462661743164,
          937.226936340332,
          489.52680587768555,
          363.4047203063965,
          308.17417430877686,
          266.51551580429077,
          228.6740665435791,
          193.7853660583496,
          162.01329565048218,
          133.34674453735352,
          108.21253490447998,
          86.58363080024719,
          68.62874329090118,
          54.00878667831421,
          42.68339943885803,
          34.193840742111206,
          28.07586282491684,
          23.80524456501007,
          20.91368418931961,
          18.971927285194397,
          17.61231157183647,
          16.54168364405632,
          15.632301032543182,
          14.833426207304,
          15.072603940963745,
          14.115098804235458
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training History - MVL_10000_40_20_20_0_10000.pickle"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          30107.134765625,
          30057.53466796875,
          29840.82470703125,
          29764.29150390625,
          29580.8916015625,
          29501.59326171875,
          29266.06591796875,
          28986.01171875,
          29207.578125,
          28445.55078125,
          27774.25732421875,
          27771.7099609375,
          27917.30126953125,
          26810.0595703125,
          26821.2509765625,
          26554.5751953125,
          25593.181640625,
          25086.62060546875,
          24813.0537109375,
          23947.83935546875,
          23212.1416015625,
          22345.70947265625,
          21895.93310546875,
          21237.25,
          20251.072265625,
          20389.33642578125,
          19338.55029296875,
          18558.7646484375,
          17401.398681640625,
          17470.63525390625
         ]
        },
        {
         "name": "Test Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          30518.351135253906,
          30413.393493652344,
          30289.284301757812,
          30143.923767089844,
          29975.029724121094,
          29780.90283203125,
          29559.52801513672,
          29309.05126953125,
          29028.446899414062,
          28716.279846191406,
          28372.792236328125,
          27997.46875,
          27588.90447998047,
          27147.53143310547,
          26674.26641845703,
          26168.464477539062,
          25631.975524902344,
          25068.556762695312,
          24478.417907714844,
          23862.76336669922,
          23226.89501953125,
          22573.515380859375,
          21906.624755859375,
          21226.23077392578,
          20537.010620117188,
          19841.256591796875,
          19139.572387695312,
          18436.95977783203,
          17738.419982910156,
          17048.289001464844
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training History - PTR_10000_40_20_5_0_100.pickle"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n",
      "Invalid input. Please try again.\n",
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n",
      "Invalid input. Please try again.\n",
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n",
      "Invalid input. Please try again.\n",
      "Select a file to display:\n",
      "1: MVL_10000_40_20_20_0_10000.pickle\n",
      "2: PTR_10000_40_20_5_0_100.pickle\n",
      "3: TR_10000_20_10_20_0_10000.pickle\n",
      "4: RRR_10000_20_10_20_0_100.pickle\n",
      "5: TR_10000_40_20_20_0_1000.pickle\n",
      "6: RRR_10000_40_20_5_0_10000.pickle\n",
      "7: TR_10000_40_20_20_0_10000.pickle\n",
      "8: PTR_10000_40_20_20_0_10000.pickle\n",
      "9: RRR_10000_40_20_5_0_1000.pickle\n",
      "10: MVL_10000_40_20_20_0_100.pickle\n",
      "11: MVL_10000_20_10_5_0_100.pickle\n",
      "12: MVL_10000_20_10_5_0_1000.pickle\n",
      "13: MVL_10000_20_10_20_0_100.pickle\n",
      "14: MVL_10000_20_10_20_0_1000.pickle\n",
      "15: RRR_10000_20_10_5_0_10000.pickle\n",
      "16: MVL_10000_40_20_20_0_1000.pickle\n",
      "17: TR_10000_40_20_5_0_100.pickle\n",
      "18: MVL_10000_40_20_5_0_10000.pickle\n",
      "19: PTR_10000_40_20_20_0_100.pickle\n",
      "20: RRR_10000_20_10_20_0_10000.pickle\n",
      "21: RRR_10000_20_10_5_0_1000.pickle\n",
      "22: TR_10000_20_10_5_0_100.pickle\n",
      "23: TR_10000_20_10_5_0_10000.pickle\n",
      "24: TR_10000_20_10_5_0_1000.pickle\n",
      "25: RRR_10000_20_10_20_0_1000.pickle\n",
      "26: PTR_10000_20_10_20_0_1000.pickle\n",
      "27: RRR_10000_20_10_5_0_100.pickle\n",
      "28: RRR_10000_40_20_20_0_10000.pickle\n",
      "29: RRR_10000_40_20_20_0_100.pickle\n",
      "30: MVL_10000_40_20_5_0_100.pickle\n",
      "31: PTR_10000_20_10_20_0_100.pickle\n",
      "32: TR_10000_20_10_20_0_1000.pickle\n",
      "33: PTR_10000_20_10_20_0_10000.pickle\n",
      "34: MVL_10000_40_20_5_0_1000.pickle\n",
      "35: PTR_10000_40_20_5_0_10000.pickle\n",
      "36: PTR_10000_40_20_5_0_1000.pickle\n",
      "37: MVL_10000_20_10_5_0_10000.pickle\n",
      "38: TR_10000_20_10_20_0_100.pickle\n",
      "39: RRR_10000_40_20_20_0_1000.pickle\n",
      "40: RRR_10000_40_20_5_0_100.pickle\n",
      "41: MVL_10000_20_10_20_0_10000.pickle\n",
      "42: PTR_10000_40_20_20_0_1000.pickle\n",
      "43: TR_10000_40_20_5_0_10000.pickle\n",
      "44: TR_10000_40_20_5_0_1000.pickle\n",
      "45: TR_10000_40_20_20_0_100.pickle\n",
      "46: PTR_10000_20_10_5_0_100.pickle\n",
      "47: PTR_10000_20_10_5_0_10000.pickle\n",
      "48: PTR_10000_20_10_5_0_1000.pickle\n",
      "Type 'Exit' to quit.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define the path to the folder containing the pickle files\n",
    "folder_path = \"./training_history/\"\n",
    "\n",
    "# Get a list of all the pickle files in the folder\n",
    "pickle_files = [f for f in os.listdir(folder_path) if f.endswith(\".pickle\")]\n",
    "\n",
    "# Loop to allow the user to select multiple files to display\n",
    "while True:\n",
    "    # Ask the user to select a file to display\n",
    "    print(\"Select a file to display:\")\n",
    "    for i, filename in enumerate(pickle_files):\n",
    "        print(f\"{i+1}: {filename}\")\n",
    "    print(\"Type 'Exit' to quit.\")\n",
    "    user_input = input()\n",
    "    \n",
    "    # Exit the loop if the user enters \"Exit\"\n",
    "    if user_input == \"Exit\":\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        file_index = int(user_input) - 1\n",
    "        selected_file = pickle_files[file_index]\n",
    "        # Read the selected pickle file into a DataFrame\n",
    "        filepath = os.path.join(folder_path, selected_file)\n",
    "        df = pd.read_pickle(filepath)\n",
    "\n",
    "        # Create a figure object\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add \"TrainLoss\" and \"TestLoss\" as two separate lines to the figure\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[\"TrainLoss\"], name=\"Train Loss\"))\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[\"TestLoss\"], name=\"Test Loss\"))\n",
    "\n",
    "        # Customize the layout of the figure\n",
    "        fig.update_layout(title=f\"Training History - {selected_file}\", xaxis_title=\"Time\", yaxis_title=\"Loss\")\n",
    "\n",
    "        # Show the figure in a web browser\n",
    "        pio.show(fig)\n",
    "    except:\n",
    "        print(\"Invalid input. Please try again.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial race regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f344f09ad85c48a6b61226e5b63559bfdfba5cc17c213800e000919234807efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
